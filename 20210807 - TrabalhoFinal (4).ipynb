{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo Naive é 52.5%\n",
      "A acurácia assumindo que todos são 0 é 57.7%\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "### Importação de pacotes PYTHON ###\n",
    "####################################\n",
    "# geral\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ta.utils import dropna\n",
    "from ta.volatility import BollingerBands\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "# rede neural\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "%matplotlib inline\n",
    "\n",
    "#########################################\n",
    "### Importação da base do mini-índice ###\n",
    "#########################################\n",
    "data = pd.read_csv('data.csv', sep='\\t')\n",
    "\n",
    "##########################################################################\n",
    "### Definindo funções básicas - acuracia e separação de treino e teste ###\n",
    "##########################################################################\n",
    "# função acuracia\n",
    "def acuracia(y_real, y_pred):\n",
    "    return sum(y_real == y_pred) / len(y_pred)\n",
    "\n",
    "# função para Separação de treino e teste\n",
    "def split_treino_test(data):\n",
    "    train = data[data['datetime'] < '2020-07-01']\n",
    "    teste = data[data['datetime'] >= '2020-07-01']\n",
    "    return train, teste\n",
    "\n",
    "####################################\n",
    "### Tratamentos básicos de datas ###\n",
    "####################################\n",
    "data['datetime'] = data['DATE'] + ' ' + data['TIME']\n",
    "data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "# Ordena base de dados por datetime\n",
    "data.sort_values(by = 'datetime', inplace = True)\n",
    "# Mantém apenas as variáveis datetime, tickvol e close \n",
    "data = data[['datetime', 'TICKVOL', 'CLOSE']]\n",
    "\n",
    "########################################\n",
    "### Criando variável resposta target ###\n",
    "########################################\n",
    "data.rename(columns = {'CLOSE':'valor'}, inplace = True)\n",
    "data.loc[:,'target_num'] = data['valor'].shift(-1)\n",
    "data.loc[:,'target_diff'] = data['target_num']  - data['valor']\n",
    "# cria variável target pela diferença entre a leitura do close atual \n",
    "# com a próxima leitura (leitura de 1 minuto posterior)\n",
    "data.loc[:,'target'] = data['target_diff'].apply(lambda x: 1 if x>=10 else 0)\n",
    "data = data.drop(columns = ['target_num', 'target_diff'])\n",
    "\n",
    "########################################\n",
    "### remoção da primeira linha do dia ###\n",
    "########################################\n",
    "data['primeira_do_dia'] = data['datetime'].diff() > pd.Timedelta(10, unit = 'hour')\n",
    "data = data.loc[data['primeira_do_dia'] == False]\n",
    "data = data[['datetime', 'valor', 'TICKVOL','target']].reset_index(drop = True)\n",
    "\n",
    "###################################\n",
    "### Criação de modelos baseline ###\n",
    "###################################\n",
    "\n",
    "#Criação de um modelo baseline utilizando 'naive', para servir como comparação para os modelos que serão criados. \n",
    "# Criação de variável target com lag\n",
    "_, teste = split_treino_test(data)\n",
    "\n",
    "teste_naive = teste.copy()\n",
    "\n",
    "teste_naive['target_l1'] = teste_naive['target'].shift(1)\n",
    "teste_naive=teste_naive.dropna()\n",
    "\n",
    "# A predição é simplesmente o time step anterior\n",
    "performance_baseline = acuracia(teste_naive['target'], teste_naive['target_l1'])\n",
    "print(\"A acurácia do modelo Naive é \" + str(round(100*performance_baseline,1)) + \"%\")\n",
    "\n",
    "# Outra predição Naive seria assumir que todos os resultados são 0:\n",
    "qtdade_zeros_base = 1-teste_naive['target'].mean()\n",
    "print(\"A acurácia assumindo que todos são 0 é \" + str(round(100*qtdade_zeros_base,1)) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>valor</th>\n",
       "      <th>TICKVOL</th>\n",
       "      <th>target</th>\n",
       "      <th>c_ma20</th>\n",
       "      <th>c_ma10</th>\n",
       "      <th>c_ma10/ma20</th>\n",
       "      <th>c_ma20_maior_ma10</th>\n",
       "      <th>c_max20</th>\n",
       "      <th>c_max10</th>\n",
       "      <th>...</th>\n",
       "      <th>valor_target_l15</th>\n",
       "      <th>valor_target_l16</th>\n",
       "      <th>valor_target_l17</th>\n",
       "      <th>valor_target_l18</th>\n",
       "      <th>valor_target_l19</th>\n",
       "      <th>valor_target_l20</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>hora_do_dia</th>\n",
       "      <th>dia_do_mes</th>\n",
       "      <th>periodo_dia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-09 09:20:00</td>\n",
       "      <td>1.137678</td>\n",
       "      <td>0.333476</td>\n",
       "      <td>0</td>\n",
       "      <td>1.137225</td>\n",
       "      <td>1.137527</td>\n",
       "      <td>1.000274</td>\n",
       "      <td>0</td>\n",
       "      <td>1.135332</td>\n",
       "      <td>1.136222</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-09 09:21:00</td>\n",
       "      <td>1.137371</td>\n",
       "      <td>0.342275</td>\n",
       "      <td>0</td>\n",
       "      <td>1.137302</td>\n",
       "      <td>1.137517</td>\n",
       "      <td>1.000198</td>\n",
       "      <td>0</td>\n",
       "      <td>1.135332</td>\n",
       "      <td>1.136222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-09 09:22:00</td>\n",
       "      <td>1.137269</td>\n",
       "      <td>0.339812</td>\n",
       "      <td>1</td>\n",
       "      <td>1.137319</td>\n",
       "      <td>1.137492</td>\n",
       "      <td>1.000160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.135332</td>\n",
       "      <td>1.136222</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-09 09:23:00</td>\n",
       "      <td>1.137422</td>\n",
       "      <td>0.271708</td>\n",
       "      <td>0</td>\n",
       "      <td>1.137348</td>\n",
       "      <td>1.137487</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>0</td>\n",
       "      <td>1.135332</td>\n",
       "      <td>1.136222</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-09 09:24:00</td>\n",
       "      <td>1.137371</td>\n",
       "      <td>0.165242</td>\n",
       "      <td>0</td>\n",
       "      <td>1.137358</td>\n",
       "      <td>1.137466</td>\n",
       "      <td>1.000103</td>\n",
       "      <td>0</td>\n",
       "      <td>1.135332</td>\n",
       "      <td>1.136222</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96199</th>\n",
       "      <td>2020-08-31 17:50:00</td>\n",
       "      <td>1.019978</td>\n",
       "      <td>0.893435</td>\n",
       "      <td>0</td>\n",
       "      <td>1.020441</td>\n",
       "      <td>1.020558</td>\n",
       "      <td>1.000123</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019355</td>\n",
       "      <td>1.020154</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96200</th>\n",
       "      <td>2020-08-31 17:51:00</td>\n",
       "      <td>1.019671</td>\n",
       "      <td>0.372895</td>\n",
       "      <td>1</td>\n",
       "      <td>1.020398</td>\n",
       "      <td>1.020558</td>\n",
       "      <td>1.000165</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019355</td>\n",
       "      <td>1.020154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96201</th>\n",
       "      <td>2020-08-31 17:52:00</td>\n",
       "      <td>1.020029</td>\n",
       "      <td>0.199382</td>\n",
       "      <td>0</td>\n",
       "      <td>1.020372</td>\n",
       "      <td>1.020543</td>\n",
       "      <td>1.000175</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019355</td>\n",
       "      <td>1.020154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96202</th>\n",
       "      <td>2020-08-31 17:53:00</td>\n",
       "      <td>1.019467</td>\n",
       "      <td>0.216804</td>\n",
       "      <td>1</td>\n",
       "      <td>1.020318</td>\n",
       "      <td>1.020481</td>\n",
       "      <td>1.000168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019355</td>\n",
       "      <td>1.020154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96203</th>\n",
       "      <td>2020-08-31 17:54:00</td>\n",
       "      <td>1.019825</td>\n",
       "      <td>0.432199</td>\n",
       "      <td>0</td>\n",
       "      <td>1.020301</td>\n",
       "      <td>1.020446</td>\n",
       "      <td>1.000150</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019355</td>\n",
       "      <td>1.020154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96204 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime     valor   TICKVOL  target    c_ma20    c_ma10  \\\n",
       "0     2019-12-09 09:20:00  1.137678  0.333476       0  1.137225  1.137527   \n",
       "1     2019-12-09 09:21:00  1.137371  0.342275       0  1.137302  1.137517   \n",
       "2     2019-12-09 09:22:00  1.137269  0.339812       1  1.137319  1.137492   \n",
       "3     2019-12-09 09:23:00  1.137422  0.271708       0  1.137348  1.137487   \n",
       "4     2019-12-09 09:24:00  1.137371  0.165242       0  1.137358  1.137466   \n",
       "...                   ...       ...       ...     ...       ...       ...   \n",
       "96199 2020-08-31 17:50:00  1.019978  0.893435       0  1.020441  1.020558   \n",
       "96200 2020-08-31 17:51:00  1.019671  0.372895       1  1.020398  1.020558   \n",
       "96201 2020-08-31 17:52:00  1.020029  0.199382       0  1.020372  1.020543   \n",
       "96202 2020-08-31 17:53:00  1.019467  0.216804       1  1.020318  1.020481   \n",
       "96203 2020-08-31 17:54:00  1.019825  0.432199       0  1.020301  1.020446   \n",
       "\n",
       "       c_ma10/ma20  c_ma20_maior_ma10   c_max20   c_max10  ...  \\\n",
       "0         1.000274                  0  1.135332  1.136222  ...   \n",
       "1         1.000198                  0  1.135332  1.136222  ...   \n",
       "2         1.000160                  0  1.135332  1.136222  ...   \n",
       "3         1.000130                  0  1.135332  1.136222  ...   \n",
       "4         1.000103                  0  1.135332  1.136222  ...   \n",
       "...            ...                ...       ...       ...  ...   \n",
       "96199     1.000123                  0  1.019355  1.020154  ...   \n",
       "96200     1.000165                  0  1.019355  1.020154  ...   \n",
       "96201     1.000175                  0  1.019355  1.020154  ...   \n",
       "96202     1.000168                  0  1.019355  1.020154  ...   \n",
       "96203     1.000150                  0  1.019355  1.020154  ...   \n",
       "\n",
       "       valor_target_l15  valor_target_l16  valor_target_l17  valor_target_l18  \\\n",
       "0                   1.0               0.0               1.0               0.0   \n",
       "1                   0.0               1.0               0.0               1.0   \n",
       "2                   1.0               0.0               1.0               0.0   \n",
       "3                   1.0               1.0               0.0               1.0   \n",
       "4                   1.0               1.0               1.0               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "96199               1.0               1.0               0.0               0.0   \n",
       "96200               0.0               1.0               1.0               0.0   \n",
       "96201               0.0               0.0               1.0               1.0   \n",
       "96202               0.0               0.0               0.0               1.0   \n",
       "96203               0.0               0.0               0.0               0.0   \n",
       "\n",
       "       valor_target_l19  valor_target_l20  dia_semana  hora_do_dia  \\\n",
       "0                   1.0               1.0           0            9   \n",
       "1                   0.0               1.0           0            9   \n",
       "2                   1.0               0.0           0            9   \n",
       "3                   0.0               1.0           0            9   \n",
       "4                   1.0               0.0           0            9   \n",
       "...                 ...               ...         ...          ...   \n",
       "96199               0.0               1.0           0           17   \n",
       "96200               0.0               0.0           0           17   \n",
       "96201               0.0               0.0           0           17   \n",
       "96202               1.0               0.0           0           17   \n",
       "96203               1.0               1.0           0           17   \n",
       "\n",
       "       dia_do_mes  periodo_dia  \n",
       "0               1            1  \n",
       "1               1            1  \n",
       "2               1            1  \n",
       "3               1            1  \n",
       "4               1            1  \n",
       "...           ...          ...  \n",
       "96199           3            3  \n",
       "96200           3            3  \n",
       "96201           3            3  \n",
       "96202           3            3  \n",
       "96203           3            3  \n",
       "\n",
       "[96204 rows x 130 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################################\n",
    "### Criação de variáveis baseadas nos fechamentos e no tickvol ###\n",
    "##################################################################\n",
    "\n",
    "#########################################\n",
    "### criando uma cópia da base inicial ###\n",
    "#########################################\n",
    "data_1 = data.copy()\n",
    "\n",
    "###################################\n",
    "### variáveis baseadas em close ###\n",
    "###################################\n",
    "d = pd.Series(data[\"valor\"])\n",
    "\n",
    "# variáveis de médias móveis 20 e 10 minutos\n",
    "data_1['c_ma20'] = d.rolling(20).mean()\n",
    "data_1['c_ma10'] = d.rolling(10).mean()\n",
    "\n",
    "# comparando média móvel de 20 minutos com média móvel de 10 minutos\n",
    "data_1['c_ma10/ma20'] = data_1['c_ma10']/data_1['c_ma20']\n",
    "data_1['c_ma20_maior_ma10'] = np.where((data_1.c_ma20 > data_1.c_ma10),1,0)\n",
    "\n",
    "# variáveis com máximo e mínimo de 20 e 10 minutos\n",
    "data_1['c_max20'] = d.rolling(20).max()\n",
    "data_1['c_max10'] = d.rolling(10).max()\n",
    "data_1['c_min20'] = d.rolling(20).min()\n",
    "data_1['c_min10'] = d.rolling(10).min()\n",
    "data_1['c_max10/max20'] = data_1['c_max10']/data_1['c_max20']\n",
    "data_1['c_max10/min20'] = data_1['c_max10']/data_1['c_min20']\n",
    "data_1['c_min10/max20'] = data_1['c_min10']/data_1['c_max20']\n",
    "data_1['c_min10/min20'] = data_1['c_min10']/data_1['c_min20']\n",
    "data_1['c_min10/max10'] = data_1['c_min10']/data_1['c_max10']\n",
    "data_1['c_min20/max20'] = data_1['c_min20']/data_1['c_max20']\n",
    "\n",
    "# comparações entre mínimo, máximo e médias móveis\n",
    "data_1['c_ma10/max20'] = data_1['c_ma10']/data_1['c_max20']\n",
    "data_1['c_ma10/ma20'] = data_1['c_ma10']/data_1['c_ma20']\n",
    "data_1['c_ma10/min20'] = data_1['c_ma10']/data_1['c_min20']\n",
    "data_1['c_ma10/min10'] = data_1['c_ma10']/data_1['c_min10']\n",
    "data_1['c_ma10/max10'] = data_1['c_ma10']/data_1['c_max10']\n",
    "data_1['c_ma20/max20'] = data_1['c_ma20']/data_1['c_max20']\n",
    "data_1['c_ma20/min20'] = data_1['c_ma20']/data_1['c_min20']\n",
    "data_1['c_ma20/min10'] = data_1['c_ma20']/data_1['c_min10']\n",
    "data_1['c_ma20/max10'] = data_1['c_ma20']/data_1['c_max10']\n",
    "data_1['c_ma10_maior_max20'] = np.where((data_1.c_ma10 > data_1.c_max20),1,0)\n",
    "data_1['c_ma20_menor_min10'] = np.where((data_1.c_ma20 < data_1.c_min10),1,0)\n",
    "data_1['c_ma10_menor_min20'] = np.where((data_1.c_ma10 < data_1.c_min20),1,0)\n",
    "\n",
    "# comparações entre ponto atual e máximos e mínimos de 10 e 20 minutos\n",
    "data_1['c_valor_menor_min20'] = np.where((data_1.valor < data_1.c_min20),1,0)\n",
    "data_1['c_valor_menor_min10'] = np.where((data_1.valor < data_1.c_min10),1,0)\n",
    "data_1['c_valor_maior_max20'] = np.where((data_1.valor > data_1.c_max20),1,0)\n",
    "data_1['c_valor_maior_max10'] = np.where((data_1.valor > data_1.c_max10),1,0)\n",
    "\n",
    "# criação das bollinger bands considerando n = 20 minutos e 2 desvios padrão\n",
    "indicator_bb = BollingerBands(close=data_1[\"valor\"], n=20, ndev=2)\n",
    "data_1['c_bb_bbp'] = indicator_bb.bollinger_pband()\n",
    "data_1['c_bb_upper'] = indicator_bb.bollinger_hband_indicator()\n",
    "data_1['c_bb_lower'] = indicator_bb.bollinger_lband_indicator()\n",
    "\n",
    "# criação do fechamento lagado de até 3 minutos\n",
    "data_1['c_valor_l1'] = data_1['valor'].shift(1)\n",
    "data_1['c_valor_l2'] = data_1['valor'].shift(2)\n",
    "data_1['c_valor_l3'] = data_1['valor'].shift(3)\n",
    "# comparação entre o valor de fechamento atual e os fechamentos lagados\n",
    "data_1['c_diff_l1'] = data_1['valor']  - data_1['c_valor_l1']\n",
    "data_1['c_diff_l2'] = data_1['valor']  - data_1['c_valor_l2']\n",
    "data_1['c_diff_l3'] = data_1['valor']  - data_1['c_valor_l3']\n",
    "# comparação entre o valor de fechamento lagado de 1 minuto e fechamento lagado de 20 minutos\n",
    "data_1['c_lag1/lag20'] = data_1['valor'].shift(1)/data_1['valor'].shift(20)\n",
    "data_1['c_lag1/lag10'] = data_1['valor'].shift(1)/data_1['valor'].shift(10)\n",
    "data_1['c_coef_ang20'] = (data_1['c_valor_l1'] - data_1['valor'].shift(20))/20\n",
    "data_1['c_coef_ang10'] = (data_1['c_valor_l1'] - data_1['valor'].shift(10))/10\n",
    "\n",
    "# quantidade de vezes que o índice fechou positivo ou negativo em relação ao minuto anterior \n",
    "# nos últimos 20 minutos e 10 minutos\n",
    "x = 0\n",
    "y = 0\n",
    "for i in range(1,19):\n",
    "    x = np.where((data_1['valor'].shift(i) > data_1['valor'].shift(i+1)),1,0) + x\n",
    "    y = np.where((data_1['valor'].shift(i) < data_1['valor'].shift(i+1)),1,0) + y\n",
    "    \n",
    "a = 0\n",
    "b = 0\n",
    "for i in range(1,9):\n",
    "    a = np.where((data_1['valor'].shift(i) > data_1['valor'].shift(i+1)),1,0) + a\n",
    "    b = np.where((data_1['valor'].shift(i) < data_1['valor'].shift(i+1)),1,0) + b\n",
    "    \n",
    "data_1['c_qtde_vezes_positivo20'] = x\n",
    "data_1['c_qtde_vezes_negativo20'] = y\n",
    "data_1['c_qtde_vezes_positivo10'] = a\n",
    "data_1['c_qtde_vezes_negativo10'] = b\n",
    "\n",
    "# variáveis lagadas vs mínimos, média móvel \n",
    "data_1['c_lag1/min20'] = data_1['valor'].shift(1)/data_1['c_min20']\n",
    "data_1['c_lag2/min20'] = data_1['valor'].shift(2)/data_1['c_min20']\n",
    "data_1['c_lag3/min20'] = data_1['valor'].shift(3)/data_1['c_min20']\n",
    "data_1['c_lag1/ma20'] = data_1['valor'].shift(1)/data_1['c_ma20']\n",
    "\n",
    "# variável média vs máximo\n",
    "data_1['c_ma3/max3'] = d.rolling(3).mean()/d.rolling(3).max()\n",
    "\n",
    "# normalizando\n",
    "media = data_1['c_ma20'].mean()\n",
    "data_1['c_ma20'] = data_1['c_ma20']/media\n",
    "media = data_1['c_ma10'].mean()\n",
    "data_1['c_ma10'] = data_1['c_ma10']/media\n",
    "\n",
    "media = data_1['c_max20'].mean()\n",
    "data_1['c_max20'] = data_1['c_max20']/media\n",
    "media = data_1['c_max10'].mean()\n",
    "data_1['c_max10'] = data_1['c_max10']/media\n",
    "media = data_1['c_min20'].mean()\n",
    "data_1['c_min20'] = data_1['c_min20']/media\n",
    "media = data_1['c_min10'].mean()\n",
    "data_1['c_min10'] = data_1['c_min10']/media\n",
    "\n",
    "media = data_1['c_bb_upper'].mean()\n",
    "data_1['c_bb_upper'] = data_1['c_bb_upper']/media\n",
    "media = data_1['c_bb_lower'].mean()\n",
    "data_1['c_bb_lower'] = data_1['c_bb_lower']/media\n",
    "\n",
    "media = data_1['c_valor_l1'].mean()\n",
    "data_1['c_valor_l1'] = data_1['c_valor_l1']/media\n",
    "media = data_1['c_valor_l2'].mean()\n",
    "data_1['c_valor_l2'] = data_1['c_valor_l2']/media\n",
    "media = data_1['c_valor_l3'].mean()\n",
    "data_1['c_valor_l3'] = data_1['c_valor_l3']/media\n",
    "\n",
    "media = data_1['c_diff_l1'].mean()\n",
    "data_1['c_diff_l1'] = data_1['c_diff_l1']/media\n",
    "media = data_1['c_diff_l2'].mean()\n",
    "data_1['c_diff_l2'] = data_1['c_diff_l2']/media\n",
    "media = data_1['c_diff_l3'].mean()\n",
    "data_1['c_diff_l3'] = data_1['c_diff_l3']/media\n",
    "\n",
    "media = data_1['c_coef_ang20'].mean()\n",
    "data_1['c_coef_ang20'] = data_1['c_coef_ang20']/media\n",
    "media = data_1['c_coef_ang10'].mean()\n",
    "data_1['c_coef_ang10'] = data_1['c_coef_ang10']/media\n",
    "\n",
    "media = data_1['c_qtde_vezes_positivo20'].mean()\n",
    "data_1['c_qtde_vezes_positivo20'] = data_1['c_qtde_vezes_positivo20']/media\n",
    "media = data_1['c_qtde_vezes_negativo20'].mean()\n",
    "data_1['c_qtde_vezes_negativo20'] = data_1['c_qtde_vezes_negativo20']/media\n",
    "media = data_1['c_qtde_vezes_positivo10'].mean()\n",
    "data_1['c_qtde_vezes_positivo10'] = data_1['c_qtde_vezes_positivo10']/media\n",
    "media = data_1['c_qtde_vezes_negativo10'].mean()\n",
    "data_1['c_qtde_vezes_negativo10'] = data_1['c_qtde_vezes_negativo10']/media\n",
    "\n",
    "media = data_1['valor'].mean()\n",
    "data_1['valor'] = data_1['valor']/media\n",
    "\n",
    "#####################################\n",
    "### variáveis baseadas em tickvol ###\n",
    "#####################################\n",
    "a = pd.Series(data[\"TICKVOL\"])\n",
    "\n",
    "# variáveis de médias móveis 20 e 10 minutos\n",
    "data_1['t_ma20'] = a.rolling(20).mean()\n",
    "data_1['t_ma10'] = a.rolling(10).mean()\n",
    "# comparando média móvel de 20 minutos com média móvel de 10 minutos\n",
    "data_1['t_ma10/ma20'] = data_1['t_ma10']/data_1['t_ma20']\n",
    "data_1['t_ma20_maior_ma10'] = np.where((data_1.t_ma20 > data_1.t_ma10),1,0)\n",
    "\n",
    "# variáveis com máximo e mínimo de 20 e 10 minutos\n",
    "data_1['t_max20'] = a.rolling(20).max()\n",
    "data_1['t_max10'] = a.rolling(10).max()\n",
    "data_1['t_min20'] = a.rolling(20).min()\n",
    "data_1['t_min10'] = a.rolling(10).min()\n",
    "data_1['t_max10/max20'] = data_1['t_max10']/data_1['t_max20']\n",
    "data_1['t_max10/min20'] = data_1['t_max10']/data_1['t_min20']\n",
    "data_1['t_min10/max20'] = data_1['t_min10']/data_1['t_max20']\n",
    "data_1['t_min10/min20'] = data_1['t_min10']/data_1['t_min20']\n",
    "data_1['t_min10/max10'] = data_1['t_min10']/data_1['t_max10']\n",
    "data_1['t_min20/max20'] = data_1['t_min20']/data_1['t_max20']\n",
    "\n",
    "# comparações entre mínimo, máximo e médias móveis\n",
    "data_1['t_ma10/max20'] = data_1['t_ma10']/data_1['t_max20']\n",
    "data_1['t_ma10/ma20'] = data_1['t_ma10']/data_1['t_ma20']\n",
    "data_1['t_ma10/min20'] = data_1['t_ma10']/data_1['t_min20']\n",
    "data_1['t_ma10/min10'] = data_1['t_ma10']/data_1['t_min10']\n",
    "data_1['t_ma10/max10'] = data_1['t_ma10']/data_1['t_max10']\n",
    "data_1['t_ma20/max20'] = data_1['t_ma20']/data_1['t_max20']\n",
    "data_1['t_ma20/min20'] = data_1['t_ma20']/data_1['t_min20']\n",
    "data_1['t_ma20/min10'] = data_1['t_ma20']/data_1['t_min10']\n",
    "data_1['t_ma20/max10'] = data_1['t_ma20']/data_1['t_max10']\n",
    "data_1['t_ma10_maior_max20'] = np.where((data_1.t_ma10 > data_1.t_max20),1,0)\n",
    "data_1['t_ma20_menor_min10'] = np.where((data_1.t_ma20 < data_1.t_min10),1,0)\n",
    "data_1['t_ma10_menor_min20'] = np.where((data_1.t_ma10 < data_1.t_min20),1,0)\n",
    "\n",
    "# comparações entre ponto atual e máximos e mínimos de 10 e 20 minutos\n",
    "data_1['t_valor_menor_min20'] = np.where((data_1.TICKVOL < data_1.t_min20),1,0)\n",
    "data_1['t_valor_menor_min10'] = np.where((data_1.TICKVOL < data_1.t_min10),1,0)\n",
    "data_1['t_valor_maior_max20'] = np.where((data_1.TICKVOL > data_1.t_max20),1,0)\n",
    "data_1['t_valor_maior_max10'] = np.where((data_1.TICKVOL > data_1.t_max10),1,0)\n",
    "\n",
    "# criação das bollinger bands considerando n = 20 minutos e 2 desvios padrão\n",
    "indicator_aa = BollingerBands(close=data_1[\"TICKVOL\"], n=20, ndev=2)\n",
    "data_1['t_bb_bbp'] = indicator_aa.bollinger_pband()\n",
    "data_1['t_bb_upper'] = indicator_aa.bollinger_hband_indicator()\n",
    "data_1['t_bb_lower'] = indicator_aa.bollinger_lband_indicator()\n",
    "\n",
    "# criação do tickvol lagado de até 3 minutos\n",
    "data_1['t_valor_l1'] = data_1['TICKVOL'].shift(1)\n",
    "data_1['t_valor_l2'] = data_1['TICKVOL'].shift(2)\n",
    "data_1['t_valor_l3'] = data_1['TICKVOL'].shift(3)\n",
    "# comparação entre o tickvol atual e o tickvol lagado\n",
    "data_1['t_diff_l1'] = data_1['TICKVOL']  - data_1['t_valor_l1']\n",
    "data_1['t_diff_l2'] = data_1['TICKVOL']  - data_1['t_valor_l2']\n",
    "data_1['t_diff_l3'] = data_1['TICKVOL']  - data_1['t_valor_l3']\n",
    "# comparação entre o tickvol lagado de 1 minuto e tickvol lagado de 20 minutos\n",
    "data_1['t_lag1/lag20'] = data_1['TICKVOL'].shift(1)/data_1['TICKVOL'].shift(20)\n",
    "data_1['t_lag1/lag10'] = data_1['TICKVOL'].shift(1)/data_1['TICKVOL'].shift(10)\n",
    "data_1['t_coef_ang20'] = (data_1['t_valor_l1'] - data_1['TICKVOL'].shift(20))/20\n",
    "data_1['t_coef_ang10'] = (data_1['t_valor_l1'] - data_1['TICKVOL'].shift(10))/10\n",
    "\n",
    "# quantidade de vezes que o tickvol fechou positivo ou negativo em relação ao minuto anterior \n",
    "# nos últimos 20 minutos e 10 minutos\n",
    "c = 0\n",
    "d = 0\n",
    "for i in range(1,19):\n",
    "    c = np.where((data_1['TICKVOL'].shift(i) > data_1['TICKVOL'].shift(i+1)),1,0) + c\n",
    "    d = np.where((data_1['TICKVOL'].shift(i) < data_1['TICKVOL'].shift(i+1)),1,0) + d\n",
    "    \n",
    "e = 0\n",
    "f = 0\n",
    "for i in range(1,9):\n",
    "    e = np.where((data_1['TICKVOL'].shift(i) > data_1['TICKVOL'].shift(i+1)),1,0) + e\n",
    "    f = np.where((data_1['TICKVOL'].shift(i) < data_1['TICKVOL'].shift(i+1)),1,0) + f\n",
    "    \n",
    "data_1['t_qtde_vezes_positivo20'] = c\n",
    "data_1['t_qtde_vezes_negativo20'] = d\n",
    "data_1['t_qtde_vezes_positivo10'] = e\n",
    "data_1['t_qtde_vezes_negativo10'] = f\n",
    "\n",
    "# variáveis lagadas vs mínimos, média móvel \n",
    "data_1['t_lag1/min20'] = data_1['TICKVOL'].shift(1)/data_1['t_min20']\n",
    "data_1['t_lag2/min20'] = data_1['TICKVOL'].shift(2)/data_1['t_min20']\n",
    "data_1['t_lag3/min20'] = data_1['TICKVOL'].shift(3)/data_1['t_min20']\n",
    "data_1['t_lag1/ma20'] = data_1['TICKVOL'].shift(1)/data_1['t_ma20']\n",
    "\n",
    "# variável média vs máximo\n",
    "data_1['t_ma3/max3'] = a.rolling(3).mean()/a.rolling(3).max()\n",
    "\n",
    "# normalizando\n",
    "media = data_1['t_ma20'].mean()\n",
    "data_1['t_ma20'] = data_1['t_ma20']/media\n",
    "media = data_1['t_ma10'].mean()\n",
    "data_1['t_ma10'] = data_1['t_ma10']/media\n",
    "\n",
    "media = data_1['t_max20'].mean()\n",
    "data_1['t_max20'] = data_1['t_max20']/media\n",
    "media = data_1['t_max10'].mean()\n",
    "data_1['t_max10'] = data_1['t_max10']/media\n",
    "media = data_1['t_min20'].mean()\n",
    "data_1['t_min20'] = data_1['t_min20']/media\n",
    "media = data_1['t_min10'].mean()\n",
    "data_1['t_min10'] = data_1['t_min10']/media\n",
    "\n",
    "media = data_1['t_bb_upper'].mean()\n",
    "data_1['t_bb_upper'] = data_1['t_bb_upper']/media\n",
    "media = data_1['t_bb_lower'].mean()\n",
    "data_1['t_bb_lower'] = data_1['t_bb_lower']/media\n",
    "\n",
    "media = data_1['t_valor_l1'].mean()\n",
    "data_1['t_valor_l1'] = data_1['t_valor_l1']/media\n",
    "media = data_1['t_valor_l2'].mean()\n",
    "data_1['t_valor_l2'] = data_1['t_valor_l2']/media\n",
    "media = data_1['t_valor_l3'].mean()\n",
    "data_1['t_valor_l3'] = data_1['t_valor_l3']/media\n",
    "\n",
    "media = data_1['t_diff_l1'].mean()\n",
    "data_1['t_diff_l1'] = data_1['t_diff_l1']/media\n",
    "media = data_1['t_diff_l2'].mean()\n",
    "data_1['t_diff_l2'] = data_1['t_diff_l2']/media\n",
    "media = data_1['t_diff_l3'].mean()\n",
    "data_1['t_diff_l3'] = data_1['t_diff_l3']/media\n",
    "\n",
    "media = data_1['t_coef_ang20'].mean()\n",
    "data_1['t_coef_ang20'] = data_1['t_coef_ang20']/media\n",
    "media = data_1['t_coef_ang10'].mean()\n",
    "data_1['t_coef_ang10'] = data_1['t_coef_ang10']/media\n",
    "\n",
    "media = data_1['t_qtde_vezes_positivo20'].mean()\n",
    "data_1['t_qtde_vezes_positivo20'] = data_1['t_qtde_vezes_positivo20']/media\n",
    "media = data_1['t_qtde_vezes_negativo20'].mean()\n",
    "data_1['t_qtde_vezes_negativo20'] = data_1['t_qtde_vezes_negativo20']/media\n",
    "media = data_1['t_qtde_vezes_positivo10'].mean()\n",
    "data_1['t_qtde_vezes_positivo10'] = data_1['t_qtde_vezes_positivo10']/media\n",
    "media = data_1['t_qtde_vezes_negativo10'].mean()\n",
    "data_1['t_qtde_vezes_negativo10'] = data_1['t_qtde_vezes_negativo10']/media\n",
    "\n",
    "media = data_1['TICKVOL'].mean()\n",
    "data_1['TICKVOL'] = data_1['TICKVOL']/media\n",
    "\n",
    "#####################\n",
    "### target lagado ###\n",
    "#####################\n",
    "data_1['valor_target_l1'] = data_1['target'].shift(1)\n",
    "data_1['valor_target_l2'] = data_1['target'].shift(2)\n",
    "data_1['valor_target_l3'] = data_1['target'].shift(3)\n",
    "data_1['valor_target_l4'] = data_1['target'].shift(4)\n",
    "data_1['valor_target_l5'] = data_1['target'].shift(5)\n",
    "data_1['valor_target_l6'] = data_1['target'].shift(6)\n",
    "data_1['valor_target_l7'] = data_1['target'].shift(7)\n",
    "data_1['valor_target_l8'] = data_1['target'].shift(8)\n",
    "data_1['valor_target_l9'] = data_1['target'].shift(9)\n",
    "data_1['valor_target_l10'] = data_1['target'].shift(10)\n",
    "data_1['valor_target_l11'] = data_1['target'].shift(11)\n",
    "data_1['valor_target_l12'] = data_1['target'].shift(12)\n",
    "data_1['valor_target_l13'] = data_1['target'].shift(13)\n",
    "data_1['valor_target_l14'] = data_1['target'].shift(14)\n",
    "data_1['valor_target_l15'] = data_1['target'].shift(15)\n",
    "data_1['valor_target_l16'] = data_1['target'].shift(16)\n",
    "data_1['valor_target_l17'] = data_1['target'].shift(17)\n",
    "data_1['valor_target_l18'] = data_1['target'].shift(18)\n",
    "data_1['valor_target_l19'] = data_1['target'].shift(19)\n",
    "data_1['valor_target_l20'] = data_1['target'].shift(20)\n",
    "\n",
    "###################################\n",
    "### variáveis baseadas em datas ###\n",
    "###################################\n",
    "# dia da semana\n",
    "data_1['dia_semana'] = pd.DatetimeIndex(data_1['datetime']).weekday # 0 é segunda #\n",
    "# hora do dia\n",
    "data_1['hora_do_dia'] = pd.DatetimeIndex(data_1['datetime']).hour\n",
    "# período do mês, inicial, meio ou final\n",
    "data_1['dia_do_mes'] = np.where((pd.DatetimeIndex(data_1['datetime']).day < 10),1,\n",
    "                               np.where((pd.DatetimeIndex(data_1['datetime']).day < 20),2,3))\n",
    "# período do dia\n",
    "data_1['periodo_dia'] = np.where((pd.DatetimeIndex(data_1['datetime']).hour < 12),1,\n",
    "                               np.where((pd.DatetimeIndex(data_1['datetime']).hour < 15),2,3))\n",
    "\n",
    "###############\n",
    "### ajustes ###\n",
    "###############\n",
    "# retira observações vazias\n",
    "data_1 = data_1.dropna()\n",
    "data_1.reset_index(drop = True, inplace = True)\n",
    "\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
      "TRAIN: [    0     1     2 ... 16031 16032 16033] TEST: [16034 16035 16036 ... 32065 32066 32067]\n",
      "TRAIN: [    0     1     2 ... 32065 32066 32067] TEST: [32068 32069 32070 ... 48099 48100 48101]\n",
      "TRAIN: [    0     1     2 ... 48099 48100 48101] TEST: [48102 48103 48104 ... 64133 64134 64135]\n",
      "TRAIN: [    0     1     2 ... 64133 64134 64135] TEST: [64136 64137 64138 ... 80167 80168 80169]\n",
      "TRAIN: [    0     1     2 ... 80167 80168 80169] TEST: [80170 80171 80172 ... 96201 96202 96203]\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    ">>> data_1X = data_1.drop(columns=['target'])\n",
    ">>> data_1X\n",
    "\n",
    ">>> data_1y = data_1[['target']]\n",
    ">>> data_1y\n",
    "\n",
    ">>> tscv = TimeSeriesSplit()\n",
    ">>> print(tscv)\n",
    "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
    ">>> for train_index, test_index in tscv.split(data_1):\n",
    "...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "...     X_teste_1= data_1X.loc[test_index]\n",
    "...     X_treino_1= data_1X.loc[train_index]\n",
    "...     y_treino_1 = data_1y.loc[train_index]\n",
    "...     y_teste_1 = data_1y.loc[test_index]\n",
    "\n",
    "...     X_treino_1['testeR']=train_index\n",
    "...     y_treino_1['testeR']=train_index\n",
    "...     X_teste_1['testeR']=test_index\n",
    "...     y_teste_1['testeR']=test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_treino_1.reset_index(drop=True)\n",
    "#y_treino_1.reset_index(drop=True)\n",
    "#X_teste_1.reset_index(drop=True)\n",
    "#y_teste_1.reset_index(drop=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "#Considering y variable holds numpy array\n",
    "\n",
    "\n",
    "X_treino_cv1 = X_treino_1[X_treino_1['testeR'] < 16034]\n",
    "X_treino_cv1 = X_treino_cv1.copy().drop(columns = ['testeR'])\n",
    "X_teste_cv1 = X_treino_1[X_treino_1['testeR'] > 16034]\n",
    "X_teste_cv1 = X_teste_cv1[X_teste_cv1['testeR'] < 32068]\n",
    "X_teste_cv1 = X_teste_cv1.copy().drop(columns = ['testeR'])\n",
    "\n",
    "X_treino_cv2 = X_treino_1[X_treino_1['testeR'] < 32068]\n",
    "X_treino_cv2 = X_treino_cv2.copy().drop(columns = ['testeR'])\n",
    "X_teste_cv2 = X_treino_1[X_treino_1['testeR'] > 32068]\n",
    "X_teste_cv2 = X_teste_cv2[X_teste_cv2['testeR'] < 48102]\n",
    "X_teste_cv2 = X_teste_cv2.copy().drop(columns = ['testeR'])\n",
    "\n",
    "X_treino_cv3 = X_treino_1[X_treino_1['testeR'] < 48101]\n",
    "X_treino_cv3 = X_treino_cv3.copy().drop(columns = ['testeR'])\n",
    "X_teste_cv3 = X_treino_1[X_treino_1['testeR'] > 48101]\n",
    "X_teste_cv3 = X_teste_cv3[X_teste_cv3['testeR'] < 64136]\n",
    "X_teste_cv3 = X_teste_cv3.copy().drop(columns = ['testeR'])\n",
    "\n",
    "X_treino_cv4 = X_treino_1[X_treino_1['testeR'] < 64135]\n",
    "X_treino_cv4 = X_treino_cv4.copy().drop(columns = ['testeR'])\n",
    "X_teste_cv4 = X_treino_1[X_treino_1['testeR'] > 64135]\n",
    "X_teste_cv4 = X_teste_cv4[X_teste_cv4['testeR'] < 80170]\n",
    "X_teste_cv4 = X_teste_cv4.copy().drop(columns = ['testeR'])\n",
    "\n",
    "X_treino_cv5 = X_treino_1.copy().drop(columns = ['testeR'])\n",
    "X_teste_cv5 = X_teste_1.copy().drop(columns = ['testeR'])\n",
    "\n",
    "\n",
    "y_treino_cv1 = y_treino_1[y_treino_1['testeR'] < 16034]\n",
    "y_treino_cv1 = y_treino_cv1.copy().drop(columns = ['testeR'])\n",
    "y_teste_cv1 = y_treino_1[y_treino_1['testeR'] > 16034]\n",
    "y_teste_cv1 = y_teste_cv1[y_teste_cv1['testeR'] < 32068]\n",
    "y_teste_cv1 = y_teste_cv1.copy().drop(columns = ['testeR'])\n",
    "\n",
    "y_treino_cv2 = y_treino_1[y_treino_1['testeR'] < 32068]\n",
    "y_treino_cv2 = y_treino_cv2.copy().drop(columns = ['testeR'])\n",
    "y_teste_cv2 = y_treino_1[y_treino_1['testeR'] > 32068]\n",
    "y_teste_cv2 = y_teste_cv2[y_teste_cv2['testeR'] < 48102]\n",
    "y_teste_cv2 = y_teste_cv2.copy().drop(columns = ['testeR'])\n",
    "\n",
    "y_treino_cv3 = y_treino_1[y_treino_1['testeR'] < 48101]\n",
    "y_treino_cv3 = y_treino_cv3.copy().drop(columns = ['testeR'])\n",
    "y_teste_cv3 = y_treino_1[y_treino_1['testeR'] > 48101]\n",
    "y_teste_cv3 = y_teste_cv3[y_teste_cv3['testeR'] < 64136]\n",
    "y_teste_cv3 = y_teste_cv3.copy().drop(columns = ['testeR'])\n",
    "\n",
    "y_treino_cv4 = y_treino_1[y_treino_1['testeR'] < 64135]\n",
    "y_treino_cv4 = y_treino_cv4.copy().drop(columns = ['testeR'])\n",
    "y_teste_cv4 = y_treino_1[y_treino_1['testeR'] > 64135]\n",
    "y_teste_cv4 = y_teste_cv4[y_teste_cv4['testeR'] < 80170]\n",
    "y_teste_cv4 = y_teste_cv4.copy().drop(columns = ['testeR'])\n",
    "\n",
    "y_treino_cv5 = y_treino_1.copy().drop(columns = ['testeR'])\n",
    "y_teste_cv5 = y_teste_1.copy().drop(columns = ['testeR'])\n",
    "\n",
    "\n",
    "y_treino_cv1 = tf.convert_to_tensor(y_treino_cv1, dtype=tf.int64)\n",
    "y_teste_cv1 = tf.convert_to_tensor(y_teste_cv1, dtype=tf.int64)\n",
    "y_treino_cv2 = tf.convert_to_tensor(y_treino_cv2, dtype=tf.int64)\n",
    "y_teste_cv2 = tf.convert_to_tensor(y_teste_cv2, dtype=tf.int64)\n",
    "y_treino_cv3 = tf.convert_to_tensor(y_treino_cv3, dtype=tf.int64)\n",
    "y_teste_cv3 = tf.convert_to_tensor(y_teste_cv3, dtype=tf.int64)\n",
    "y_treino_cv4 = tf.convert_to_tensor(y_treino_cv4, dtype=tf.int64)\n",
    "y_teste_cv4 = tf.convert_to_tensor(y_teste_cv4, dtype=tf.int64)\n",
    "y_treino_cv5 = tf.convert_to_tensor(y_treino_cv5, dtype=tf.int64)\n",
    "y_teste_cv5 = tf.convert_to_tensor(y_teste_cv5, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type Timestamp).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    465\u001b[0m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[0;32m--> 466\u001b[0;31m                   (element, type(element).__name__))\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for                  datetime     valor   TICKVOL    c_ma20    c_ma10  \\\n0     2019-12-09 09:20:00  1.137678  0.333476  1.137225  1.137527   \n1     2019-12-09 09:21:00  1.137371  0.342275  1.137302  1.137517   \n2     2019-12-09 09:22:00  1.137269  0.339812  1.137319  1.137492   \n3     2019-12-09 09:23:00  1.137422  0.271708  1.137348  1.137487   \n4     2019-12-09 09:24:00  1.137371  0.165242  1.137358  1.137466   \n...                   ...       ...       ...       ...       ...   \n16029 2020-01-23 11:04:00  1.201589  0.535322  1.201094  1.200898   \n16030 2020-01-23 11:05:00  1.201692  0.687014  1.201183  1.201005   \n16031 2020-01-23 11:06:00  1.201589  0.308136  1.201227  1.201082   \n16032 2020-01-23 11:07:00  1.201538  0.352482  1.201214  1.201148   \n16033 2020-01-23 11:08:00  1.201640  0.169994  1.201209  1.201276   \n\n       c_ma10/ma20  c_ma20_maior_ma10   c_max20   c_max10   c_min20  ...  \\\n0         1.000274                  0  1.135332  1.136222  1.138249  ...   \n1         1.000198                  0  1.135332  1.136222  1.139120  ...   \n2         1.000160                  0  1.135332  1.136222  1.139120  ...   \n3         1.000130                  0  1.135332  1.136222  1.139120  ...   \n4         1.000103                  0  1.135332  1.136222  1.139120  ...   \n...            ...                ...       ...       ...       ...  ...   \n16029     0.999845                  1  1.199316  1.200052  1.202450  ...   \n16030     0.999860                  1  1.199316  1.200154  1.202911  ...   \n16031     0.999887                  1  1.199316  1.200154  1.202911  ...   \n16032     0.999953                  1  1.199265  1.200154  1.202911  ...   \n16033     1.000064                  0  1.199214  1.200154  1.202911  ...   \n\n       valor_target_l15  valor_target_l16  valor_target_l17  valor_target_l18  \\\n0                   1.0               0.0               1.0               0.0   \n1                   0.0               1.0               0.0               1.0   \n2                   1.0               0.0               1.0               0.0   \n3                   1.0               1.0               0.0               1.0   \n4                   1.0               1.0               1.0               0.0   \n...                 ...               ...               ...               ...   \n16029               0.0               0.0               0.0               1.0   \n16030               0.0               0.0               0.0               0.0   \n16031               0.0               0.0               0.0               0.0   \n16032               0.0               0.0               0.0               0.0   \n16033               0.0               0.0               0.0               0.0   \n\n       valor_target_l19  valor_target_l20  dia_semana  hora_do_dia  \\\n0                   1.0               1.0           0            9   \n1                   0.0               1.0           0            9   \n2                   1.0               0.0           0            9   \n3                   0.0               1.0           0            9   \n4                   1.0               0.0           0            9   \n...                 ...               ...         ...          ...   \n16029               1.0               0.0           3           11   \n16030               1.0               1.0           3           11   \n16031               0.0               1.0           3           11   \n16032               0.0               0.0           3           11   \n16033               0.0               0.0           3           11   \n\n       dia_do_mes  periodo_dia  \n0               1            1  \n1               1            1  \n2               1            1  \n3               1            1  \n4               1            1  \n...           ...          ...  \n16029           3            1  \n16030           3            1  \n16031           3            1  \n16032           3            1  \n16033           3            1  \n\n[16034 rows x 129 columns] with type DataFrame",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c199f50723ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                        \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                        \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_teste_cv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste_cv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                       )\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'treino k-fold1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[1;32m    389\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m     ))\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    602\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \"\"\"\n\u001b[0;32m--> 604\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2980\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         normalized_components.append(\n\u001b[0;32m---> 98\u001b[0;31m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m     99\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    336\u001b[0m                                          as_ref=False):\n\u001b[1;32m    337\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 264\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type Timestamp)."
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "### Criação da estrutura da Rede Neural ###\n",
    "###########################################\n",
    "modelo = keras.Sequential()\n",
    "# criação da camada de entrada, ativação relu\n",
    "modelo.add(keras.layers.Dense(128, activation='relu', input_shape=(128,)))\n",
    "# criação da camada escondida com 3 neurônios, ativação relu\n",
    "modelo.add(keras.layers.Dense(3, activation='relu'))\n",
    "# criação da camada de saída, ativação sigmóide para saída em probabilidade\n",
    "modelo.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# alteração do tamanho do learning rate do otimizador SGD\n",
    "sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "modelo.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "########################################\n",
    "### treino sem cv1, avaliação em cv1 ###\n",
    "########################################\n",
    "historico1 = modelo.fit(x=X_treino_cv1, y=y_treino_cv1,\n",
    "                       epochs=10,\n",
    "                       batch_size=64, \n",
    "                       verbose = 0,\n",
    "                       validation_data=(X_teste_cv1, y_teste_cv1)\n",
    "                      )\n",
    "print('treino k-fold1')\n",
    "score_n1 = modelo.evaluate(X_treino_cv1, y_treino_cv1, verbose=0)\n",
    "print(score_n1)\n",
    "print('teste validação k-fold1')\n",
    "score_n1_t = modelo.evaluate(X_teste_cv1, y_teste_cv1, verbose=0)\n",
    "print(score_n1_t)\n",
    "\n",
    "########################################\n",
    "### treino sem cv2, avaliação em cv2 ###\n",
    "########################################\n",
    "historico2 = modelo.fit(x=X_treino_cv2, y=y_treino_cv2,\n",
    "                       epochs=10,\n",
    "                       batch_size=64, \n",
    "                       verbose = 0,\n",
    "                       validation_data=(X_teste_cv2, y_teste_cv2)\n",
    "                      )\n",
    "print('treino k-fold2')\n",
    "score_n2 = modelo.evaluate(X_treino_cv2, y_treino_cv2, verbose=0)\n",
    "print(score_n2)\n",
    "print('teste validação k-fold2')\n",
    "score_n2_t = modelo.evaluate(X_teste_cv2, y_teste_cv2, verbose=0)\n",
    "print(score_n2_t)\n",
    "\n",
    "########################################\n",
    "### treino sem cv3, avaliação em cv3 ###\n",
    "########################################\n",
    "historico3 = modelo.fit(x=X_treino_cv3, y=y_treino_cv3,\n",
    "                       epochs=10,\n",
    "                       batch_size=64, \n",
    "                       verbose = 0,\n",
    "                       validation_data=(X_teste_cv3, y_teste_cv3)\n",
    "                      )\n",
    "print('treino k-fold3')\n",
    "score_n3 = modelo.evaluate(X_treino_cv3, y_treino_cv3, verbose=0)\n",
    "print(score_n3)\n",
    "print('teste validação k-fold3')\n",
    "score_n3_t = modelo.evaluate(X_teste_cv3, y_teste_cv3, verbose=0)\n",
    "print(score_n3_t)\n",
    "\n",
    "########################################\n",
    "### treino sem cv4, avaliação em cv4 ###\n",
    "########################################\n",
    "historico4 = modelo.fit(x=X_treino_cv4, y=y_treino_cv4,\n",
    "                       epochs=10,\n",
    "                       batch_size=64, \n",
    "                       verbose = 0,\n",
    "                       validation_data=(X_teste_cv4, y_teste_cv4)\n",
    "                      )\n",
    "print('treino k-fold4')\n",
    "score_n4 = modelo.evaluate(X_treino_cv4, y_treino_cv4, verbose=0)\n",
    "print(score_n4)\n",
    "print('teste validação k-fold4')\n",
    "score_n4_t = modelo.evaluate(X_teste_cv4, y_teste_cv4, verbose=0)\n",
    "print(score_n4_t)\n",
    "\n",
    "########################################\n",
    "### treino sem cv5, avaliação em cv5 ###\n",
    "########################################\n",
    "historico5 = modelo.fit(x=X_treino_cv5, y=y_treino_cv5,\n",
    "                       epochs=10,\n",
    "                       batch_size=64, \n",
    "                       verbose = 0,\n",
    "                       validation_data=(X_teste_cv5, y_teste_cv5)\n",
    "                      )\n",
    "print('treino k-fold5')\n",
    "score_n5 = modelo.evaluate(X_treino_cv5, y_treino_cv5, verbose=0)\n",
    "print(score_n5)\n",
    "print('teste validação k-fold5')\n",
    "score_n5_t = modelo.evaluate(X_teste_cv5, y_teste_cv5, verbose=0)\n",
    "print(score_n5_t)\n",
    "\n",
    "# avaliação da acurácia nos k-folds\n",
    "print('Acurácia - Teste Validação')\n",
    "(score_n1_t[1]+score_n2_t[1]+score_n3_t[1]+score_n4_t[1]+score_n5_t[1])/5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
