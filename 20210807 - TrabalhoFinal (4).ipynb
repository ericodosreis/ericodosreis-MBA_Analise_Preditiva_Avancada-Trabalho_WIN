{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo Naive é 52.5%\n",
      "A acurácia assumindo que todos são 0 é 57.7%\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "### Importação de pacotes PYTHON ###\n",
    "####################################\n",
    "# geral\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ta.utils import dropna\n",
    "from ta.volatility import BollingerBands\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "# rede neural\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "%matplotlib inline\n",
    "\n",
    "#########################################\n",
    "### Importação da base do mini-índice ###\n",
    "#########################################\n",
    "data = pd.read_csv('data.csv', sep='\\t')\n",
    "\n",
    "##########################################################################\n",
    "### Definindo funções básicas - acuracia e separação de treino e teste ###\n",
    "##########################################################################\n",
    "# função acuracia\n",
    "def acuracia(y_real, y_pred):\n",
    "    return sum(y_real == y_pred) / len(y_pred)\n",
    "\n",
    "# função para Separação de treino e teste\n",
    "def split_treino_test(data):\n",
    "    train = data[data['datetime'] < '2020-07-01']\n",
    "    teste = data[data['datetime'] >= '2020-07-01']\n",
    "    return train, teste\n",
    "\n",
    "####################################\n",
    "### Tratamentos básicos de datas ###\n",
    "####################################\n",
    "data['datetime'] = data['DATE'] + ' ' + data['TIME']\n",
    "data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "# Ordena base de dados por datetime\n",
    "data.sort_values(by = 'datetime', inplace = True)\n",
    "# Mantém apenas as variáveis datetime, tickvol e close \n",
    "data = data[['datetime', 'TICKVOL', 'CLOSE']]\n",
    "\n",
    "########################################\n",
    "### Criando variável resposta target ###\n",
    "########################################\n",
    "data.rename(columns = {'CLOSE':'valor'}, inplace = True)\n",
    "data.loc[:,'target_num'] = data['valor'].shift(-1)\n",
    "data.loc[:,'target_diff'] = data['target_num']  - data['valor']\n",
    "# cria variável target pela diferença entre a leitura do close atual \n",
    "# com a próxima leitura (leitura de 1 minuto posterior)\n",
    "data.loc[:,'target'] = data['target_diff'].apply(lambda x: 1 if x>=10 else 0)\n",
    "data = data.drop(columns = ['target_num', 'target_diff'])\n",
    "\n",
    "########################################\n",
    "### remoção da primeira linha do dia ###\n",
    "########################################\n",
    "data['primeira_do_dia'] = data['datetime'].diff() > pd.Timedelta(10, unit = 'hour')\n",
    "data = data.loc[data['primeira_do_dia'] == False]\n",
    "data = data[['datetime', 'valor', 'TICKVOL','target']].reset_index(drop = True)\n",
    "\n",
    "###################################\n",
    "### Criação de modelos baseline ###\n",
    "###################################\n",
    "\n",
    "#Criação de um modelo baseline utilizando 'naive', para servir como comparação para os modelos que serão criados. \n",
    "# Criação de variável target com lag\n",
    "_, teste = split_treino_test(data)\n",
    "\n",
    "teste_naive = teste.copy()\n",
    "\n",
    "teste_naive['target_l1'] = teste_naive['target'].shift(1)\n",
    "teste_naive=teste_naive.dropna()\n",
    "\n",
    "# A predição é simplesmente o time step anterior\n",
    "performance_baseline = acuracia(teste_naive['target'], teste_naive['target_l1'])\n",
    "print(\"A acurácia do modelo Naive é \" + str(round(100*performance_baseline,1)) + \"%\")\n",
    "\n",
    "# Outra predição Naive seria assumir que todos os resultados são 0:\n",
    "qtdade_zeros_base = 1-teste_naive['target'].mean()\n",
    "print(\"A acurácia assumindo que todos são 0 é \" + str(round(100*qtdade_zeros_base,1)) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>valor</th>\n",
       "      <th>TICKVOL</th>\n",
       "      <th>target</th>\n",
       "      <th>c_ma20</th>\n",
       "      <th>c_ma10</th>\n",
       "      <th>c_ma10/ma20</th>\n",
       "      <th>c_ma20_maior_ma10</th>\n",
       "      <th>c_max20</th>\n",
       "      <th>c_max10</th>\n",
       "      <th>...</th>\n",
       "      <th>valor_target_l15</th>\n",
       "      <th>valor_target_l16</th>\n",
       "      <th>valor_target_l17</th>\n",
       "      <th>valor_target_l18</th>\n",
       "      <th>valor_target_l19</th>\n",
       "      <th>valor_target_l20</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>hora_do_dia</th>\n",
       "      <th>dia_do_mes</th>\n",
       "      <th>periodo_dia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-09 09:20:00</td>\n",
       "      <td>1.137678</td>\n",
       "      <td>0.333476</td>\n",
       "      <td>0</td>\n",
       "      <td>1.137225</td>\n",
       "      <td>1.137527</td>\n",
       "      <td>1.000274</td>\n",
       "      <td>0</td>\n",
       "      <td>1.135332</td>\n",
       "      <td>1.136222</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-09 09:21:00</td>\n",
       "      <td>1.137371</td>\n",
       "      <td>0.342275</td>\n",
       "      <td>0</td>\n",
       "      <td>1.137302</td>\n",
       "      <td>1.137517</td>\n",
       "      <td>1.000198</td>\n",
       "      <td>0</td>\n",
       "      <td>1.135332</td>\n",
       "      <td>1.136222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-09 09:22:00</td>\n",
       "      <td>1.137269</td>\n",
       "      <td>0.339812</td>\n",
       "      <td>1</td>\n",
       "      <td>1.137319</td>\n",
       "      <td>1.137492</td>\n",
       "      <td>1.000160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.135332</td>\n",
       "      <td>1.136222</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-09 09:23:00</td>\n",
       "      <td>1.137422</td>\n",
       "      <td>0.271708</td>\n",
       "      <td>0</td>\n",
       "      <td>1.137348</td>\n",
       "      <td>1.137487</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>0</td>\n",
       "      <td>1.135332</td>\n",
       "      <td>1.136222</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-09 09:24:00</td>\n",
       "      <td>1.137371</td>\n",
       "      <td>0.165242</td>\n",
       "      <td>0</td>\n",
       "      <td>1.137358</td>\n",
       "      <td>1.137466</td>\n",
       "      <td>1.000103</td>\n",
       "      <td>0</td>\n",
       "      <td>1.135332</td>\n",
       "      <td>1.136222</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96199</th>\n",
       "      <td>2020-08-31 17:50:00</td>\n",
       "      <td>1.019978</td>\n",
       "      <td>0.893435</td>\n",
       "      <td>0</td>\n",
       "      <td>1.020441</td>\n",
       "      <td>1.020558</td>\n",
       "      <td>1.000123</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019355</td>\n",
       "      <td>1.020154</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96200</th>\n",
       "      <td>2020-08-31 17:51:00</td>\n",
       "      <td>1.019671</td>\n",
       "      <td>0.372895</td>\n",
       "      <td>1</td>\n",
       "      <td>1.020398</td>\n",
       "      <td>1.020558</td>\n",
       "      <td>1.000165</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019355</td>\n",
       "      <td>1.020154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96201</th>\n",
       "      <td>2020-08-31 17:52:00</td>\n",
       "      <td>1.020029</td>\n",
       "      <td>0.199382</td>\n",
       "      <td>0</td>\n",
       "      <td>1.020372</td>\n",
       "      <td>1.020543</td>\n",
       "      <td>1.000175</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019355</td>\n",
       "      <td>1.020154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96202</th>\n",
       "      <td>2020-08-31 17:53:00</td>\n",
       "      <td>1.019467</td>\n",
       "      <td>0.216804</td>\n",
       "      <td>1</td>\n",
       "      <td>1.020318</td>\n",
       "      <td>1.020481</td>\n",
       "      <td>1.000168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019355</td>\n",
       "      <td>1.020154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96203</th>\n",
       "      <td>2020-08-31 17:54:00</td>\n",
       "      <td>1.019825</td>\n",
       "      <td>0.432199</td>\n",
       "      <td>0</td>\n",
       "      <td>1.020301</td>\n",
       "      <td>1.020446</td>\n",
       "      <td>1.000150</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019355</td>\n",
       "      <td>1.020154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96204 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime     valor   TICKVOL  target    c_ma20    c_ma10  \\\n",
       "0     2019-12-09 09:20:00  1.137678  0.333476       0  1.137225  1.137527   \n",
       "1     2019-12-09 09:21:00  1.137371  0.342275       0  1.137302  1.137517   \n",
       "2     2019-12-09 09:22:00  1.137269  0.339812       1  1.137319  1.137492   \n",
       "3     2019-12-09 09:23:00  1.137422  0.271708       0  1.137348  1.137487   \n",
       "4     2019-12-09 09:24:00  1.137371  0.165242       0  1.137358  1.137466   \n",
       "...                   ...       ...       ...     ...       ...       ...   \n",
       "96199 2020-08-31 17:50:00  1.019978  0.893435       0  1.020441  1.020558   \n",
       "96200 2020-08-31 17:51:00  1.019671  0.372895       1  1.020398  1.020558   \n",
       "96201 2020-08-31 17:52:00  1.020029  0.199382       0  1.020372  1.020543   \n",
       "96202 2020-08-31 17:53:00  1.019467  0.216804       1  1.020318  1.020481   \n",
       "96203 2020-08-31 17:54:00  1.019825  0.432199       0  1.020301  1.020446   \n",
       "\n",
       "       c_ma10/ma20  c_ma20_maior_ma10   c_max20   c_max10  ...  \\\n",
       "0         1.000274                  0  1.135332  1.136222  ...   \n",
       "1         1.000198                  0  1.135332  1.136222  ...   \n",
       "2         1.000160                  0  1.135332  1.136222  ...   \n",
       "3         1.000130                  0  1.135332  1.136222  ...   \n",
       "4         1.000103                  0  1.135332  1.136222  ...   \n",
       "...            ...                ...       ...       ...  ...   \n",
       "96199     1.000123                  0  1.019355  1.020154  ...   \n",
       "96200     1.000165                  0  1.019355  1.020154  ...   \n",
       "96201     1.000175                  0  1.019355  1.020154  ...   \n",
       "96202     1.000168                  0  1.019355  1.020154  ...   \n",
       "96203     1.000150                  0  1.019355  1.020154  ...   \n",
       "\n",
       "       valor_target_l15  valor_target_l16  valor_target_l17  valor_target_l18  \\\n",
       "0                   1.0               0.0               1.0               0.0   \n",
       "1                   0.0               1.0               0.0               1.0   \n",
       "2                   1.0               0.0               1.0               0.0   \n",
       "3                   1.0               1.0               0.0               1.0   \n",
       "4                   1.0               1.0               1.0               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "96199               1.0               1.0               0.0               0.0   \n",
       "96200               0.0               1.0               1.0               0.0   \n",
       "96201               0.0               0.0               1.0               1.0   \n",
       "96202               0.0               0.0               0.0               1.0   \n",
       "96203               0.0               0.0               0.0               0.0   \n",
       "\n",
       "       valor_target_l19  valor_target_l20  dia_semana  hora_do_dia  \\\n",
       "0                   1.0               1.0           0            9   \n",
       "1                   0.0               1.0           0            9   \n",
       "2                   1.0               0.0           0            9   \n",
       "3                   0.0               1.0           0            9   \n",
       "4                   1.0               0.0           0            9   \n",
       "...                 ...               ...         ...          ...   \n",
       "96199               0.0               1.0           0           17   \n",
       "96200               0.0               0.0           0           17   \n",
       "96201               0.0               0.0           0           17   \n",
       "96202               1.0               0.0           0           17   \n",
       "96203               1.0               1.0           0           17   \n",
       "\n",
       "       dia_do_mes  periodo_dia  \n",
       "0               1            1  \n",
       "1               1            1  \n",
       "2               1            1  \n",
       "3               1            1  \n",
       "4               1            1  \n",
       "...           ...          ...  \n",
       "96199           3            3  \n",
       "96200           3            3  \n",
       "96201           3            3  \n",
       "96202           3            3  \n",
       "96203           3            3  \n",
       "\n",
       "[96204 rows x 130 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################################\n",
    "### Criação de variáveis baseadas nos fechamentos e no tickvol ###\n",
    "##################################################################\n",
    "\n",
    "#########################################\n",
    "### criando uma cópia da base inicial ###\n",
    "#########################################\n",
    "data_1 = data.copy()\n",
    "\n",
    "###################################\n",
    "### variáveis baseadas em close ###\n",
    "###################################\n",
    "d = pd.Series(data[\"valor\"])\n",
    "\n",
    "# variáveis de médias móveis 20 e 10 minutos\n",
    "data_1['c_ma20'] = d.rolling(20).mean()\n",
    "data_1['c_ma10'] = d.rolling(10).mean()\n",
    "\n",
    "# comparando média móvel de 20 minutos com média móvel de 10 minutos\n",
    "data_1['c_ma10/ma20'] = data_1['c_ma10']/data_1['c_ma20']\n",
    "data_1['c_ma20_maior_ma10'] = np.where((data_1.c_ma20 > data_1.c_ma10),1,0)\n",
    "\n",
    "# variáveis com máximo e mínimo de 20 e 10 minutos\n",
    "data_1['c_max20'] = d.rolling(20).max()\n",
    "data_1['c_max10'] = d.rolling(10).max()\n",
    "data_1['c_min20'] = d.rolling(20).min()\n",
    "data_1['c_min10'] = d.rolling(10).min()\n",
    "data_1['c_max10/max20'] = data_1['c_max10']/data_1['c_max20']\n",
    "data_1['c_max10/min20'] = data_1['c_max10']/data_1['c_min20']\n",
    "data_1['c_min10/max20'] = data_1['c_min10']/data_1['c_max20']\n",
    "data_1['c_min10/min20'] = data_1['c_min10']/data_1['c_min20']\n",
    "data_1['c_min10/max10'] = data_1['c_min10']/data_1['c_max10']\n",
    "data_1['c_min20/max20'] = data_1['c_min20']/data_1['c_max20']\n",
    "\n",
    "# comparações entre mínimo, máximo e médias móveis\n",
    "data_1['c_ma10/max20'] = data_1['c_ma10']/data_1['c_max20']\n",
    "data_1['c_ma10/ma20'] = data_1['c_ma10']/data_1['c_ma20']\n",
    "data_1['c_ma10/min20'] = data_1['c_ma10']/data_1['c_min20']\n",
    "data_1['c_ma10/min10'] = data_1['c_ma10']/data_1['c_min10']\n",
    "data_1['c_ma10/max10'] = data_1['c_ma10']/data_1['c_max10']\n",
    "data_1['c_ma20/max20'] = data_1['c_ma20']/data_1['c_max20']\n",
    "data_1['c_ma20/min20'] = data_1['c_ma20']/data_1['c_min20']\n",
    "data_1['c_ma20/min10'] = data_1['c_ma20']/data_1['c_min10']\n",
    "data_1['c_ma20/max10'] = data_1['c_ma20']/data_1['c_max10']\n",
    "data_1['c_ma10_maior_max20'] = np.where((data_1.c_ma10 > data_1.c_max20),1,0)\n",
    "data_1['c_ma20_menor_min10'] = np.where((data_1.c_ma20 < data_1.c_min10),1,0)\n",
    "data_1['c_ma10_menor_min20'] = np.where((data_1.c_ma10 < data_1.c_min20),1,0)\n",
    "\n",
    "# comparações entre ponto atual e máximos e mínimos de 10 e 20 minutos\n",
    "data_1['c_valor_menor_min20'] = np.where((data_1.valor < data_1.c_min20),1,0)\n",
    "data_1['c_valor_menor_min10'] = np.where((data_1.valor < data_1.c_min10),1,0)\n",
    "data_1['c_valor_maior_max20'] = np.where((data_1.valor > data_1.c_max20),1,0)\n",
    "data_1['c_valor_maior_max10'] = np.where((data_1.valor > data_1.c_max10),1,0)\n",
    "\n",
    "# criação das bollinger bands considerando n = 20 minutos e 2 desvios padrão\n",
    "indicator_bb = BollingerBands(close=data_1[\"valor\"], n=20, ndev=2)\n",
    "data_1['c_bb_bbp'] = indicator_bb.bollinger_pband()\n",
    "data_1['c_bb_upper'] = indicator_bb.bollinger_hband_indicator()\n",
    "data_1['c_bb_lower'] = indicator_bb.bollinger_lband_indicator()\n",
    "\n",
    "# criação do fechamento lagado de até 3 minutos\n",
    "data_1['c_valor_l1'] = data_1['valor'].shift(1)\n",
    "data_1['c_valor_l2'] = data_1['valor'].shift(2)\n",
    "data_1['c_valor_l3'] = data_1['valor'].shift(3)\n",
    "# comparação entre o valor de fechamento atual e os fechamentos lagados\n",
    "data_1['c_diff_l1'] = data_1['valor']  - data_1['c_valor_l1']\n",
    "data_1['c_diff_l2'] = data_1['valor']  - data_1['c_valor_l2']\n",
    "data_1['c_diff_l3'] = data_1['valor']  - data_1['c_valor_l3']\n",
    "# comparação entre o valor de fechamento lagado de 1 minuto e fechamento lagado de 20 minutos\n",
    "data_1['c_lag1/lag20'] = data_1['valor'].shift(1)/data_1['valor'].shift(20)\n",
    "data_1['c_lag1/lag10'] = data_1['valor'].shift(1)/data_1['valor'].shift(10)\n",
    "data_1['c_coef_ang20'] = (data_1['c_valor_l1'] - data_1['valor'].shift(20))/20\n",
    "data_1['c_coef_ang10'] = (data_1['c_valor_l1'] - data_1['valor'].shift(10))/10\n",
    "\n",
    "# quantidade de vezes que o índice fechou positivo ou negativo em relação ao minuto anterior \n",
    "# nos últimos 20 minutos e 10 minutos\n",
    "x = 0\n",
    "y = 0\n",
    "for i in range(1,19):\n",
    "    x = np.where((data_1['valor'].shift(i) > data_1['valor'].shift(i+1)),1,0) + x\n",
    "    y = np.where((data_1['valor'].shift(i) < data_1['valor'].shift(i+1)),1,0) + y\n",
    "    \n",
    "a = 0\n",
    "b = 0\n",
    "for i in range(1,9):\n",
    "    a = np.where((data_1['valor'].shift(i) > data_1['valor'].shift(i+1)),1,0) + a\n",
    "    b = np.where((data_1['valor'].shift(i) < data_1['valor'].shift(i+1)),1,0) + b\n",
    "    \n",
    "data_1['c_qtde_vezes_positivo20'] = x\n",
    "data_1['c_qtde_vezes_negativo20'] = y\n",
    "data_1['c_qtde_vezes_positivo10'] = a\n",
    "data_1['c_qtde_vezes_negativo10'] = b\n",
    "\n",
    "# variáveis lagadas vs mínimos, média móvel \n",
    "data_1['c_lag1/min20'] = data_1['valor'].shift(1)/data_1['c_min20']\n",
    "data_1['c_lag2/min20'] = data_1['valor'].shift(2)/data_1['c_min20']\n",
    "data_1['c_lag3/min20'] = data_1['valor'].shift(3)/data_1['c_min20']\n",
    "data_1['c_lag1/ma20'] = data_1['valor'].shift(1)/data_1['c_ma20']\n",
    "\n",
    "# variável média vs máximo\n",
    "data_1['c_ma3/max3'] = d.rolling(3).mean()/d.rolling(3).max()\n",
    "\n",
    "# normalizando\n",
    "media = data_1['c_ma20'].mean()\n",
    "data_1['c_ma20'] = data_1['c_ma20']/media\n",
    "media = data_1['c_ma10'].mean()\n",
    "data_1['c_ma10'] = data_1['c_ma10']/media\n",
    "\n",
    "media = data_1['c_max20'].mean()\n",
    "data_1['c_max20'] = data_1['c_max20']/media\n",
    "media = data_1['c_max10'].mean()\n",
    "data_1['c_max10'] = data_1['c_max10']/media\n",
    "media = data_1['c_min20'].mean()\n",
    "data_1['c_min20'] = data_1['c_min20']/media\n",
    "media = data_1['c_min10'].mean()\n",
    "data_1['c_min10'] = data_1['c_min10']/media\n",
    "\n",
    "media = data_1['c_bb_upper'].mean()\n",
    "data_1['c_bb_upper'] = data_1['c_bb_upper']/media\n",
    "media = data_1['c_bb_lower'].mean()\n",
    "data_1['c_bb_lower'] = data_1['c_bb_lower']/media\n",
    "\n",
    "media = data_1['c_valor_l1'].mean()\n",
    "data_1['c_valor_l1'] = data_1['c_valor_l1']/media\n",
    "media = data_1['c_valor_l2'].mean()\n",
    "data_1['c_valor_l2'] = data_1['c_valor_l2']/media\n",
    "media = data_1['c_valor_l3'].mean()\n",
    "data_1['c_valor_l3'] = data_1['c_valor_l3']/media\n",
    "\n",
    "media = data_1['c_diff_l1'].mean()\n",
    "data_1['c_diff_l1'] = data_1['c_diff_l1']/media\n",
    "media = data_1['c_diff_l2'].mean()\n",
    "data_1['c_diff_l2'] = data_1['c_diff_l2']/media\n",
    "media = data_1['c_diff_l3'].mean()\n",
    "data_1['c_diff_l3'] = data_1['c_diff_l3']/media\n",
    "\n",
    "media = data_1['c_coef_ang20'].mean()\n",
    "data_1['c_coef_ang20'] = data_1['c_coef_ang20']/media\n",
    "media = data_1['c_coef_ang10'].mean()\n",
    "data_1['c_coef_ang10'] = data_1['c_coef_ang10']/media\n",
    "\n",
    "media = data_1['c_qtde_vezes_positivo20'].mean()\n",
    "data_1['c_qtde_vezes_positivo20'] = data_1['c_qtde_vezes_positivo20']/media\n",
    "media = data_1['c_qtde_vezes_negativo20'].mean()\n",
    "data_1['c_qtde_vezes_negativo20'] = data_1['c_qtde_vezes_negativo20']/media\n",
    "media = data_1['c_qtde_vezes_positivo10'].mean()\n",
    "data_1['c_qtde_vezes_positivo10'] = data_1['c_qtde_vezes_positivo10']/media\n",
    "media = data_1['c_qtde_vezes_negativo10'].mean()\n",
    "data_1['c_qtde_vezes_negativo10'] = data_1['c_qtde_vezes_negativo10']/media\n",
    "\n",
    "media = data_1['valor'].mean()\n",
    "data_1['valor'] = data_1['valor']/media\n",
    "\n",
    "#####################################\n",
    "### variáveis baseadas em tickvol ###\n",
    "#####################################\n",
    "a = pd.Series(data[\"TICKVOL\"])\n",
    "\n",
    "# variáveis de médias móveis 20 e 10 minutos\n",
    "data_1['t_ma20'] = a.rolling(20).mean()\n",
    "data_1['t_ma10'] = a.rolling(10).mean()\n",
    "# comparando média móvel de 20 minutos com média móvel de 10 minutos\n",
    "data_1['t_ma10/ma20'] = data_1['t_ma10']/data_1['t_ma20']\n",
    "data_1['t_ma20_maior_ma10'] = np.where((data_1.t_ma20 > data_1.t_ma10),1,0)\n",
    "\n",
    "# variáveis com máximo e mínimo de 20 e 10 minutos\n",
    "data_1['t_max20'] = a.rolling(20).max()\n",
    "data_1['t_max10'] = a.rolling(10).max()\n",
    "data_1['t_min20'] = a.rolling(20).min()\n",
    "data_1['t_min10'] = a.rolling(10).min()\n",
    "data_1['t_max10/max20'] = data_1['t_max10']/data_1['t_max20']\n",
    "data_1['t_max10/min20'] = data_1['t_max10']/data_1['t_min20']\n",
    "data_1['t_min10/max20'] = data_1['t_min10']/data_1['t_max20']\n",
    "data_1['t_min10/min20'] = data_1['t_min10']/data_1['t_min20']\n",
    "data_1['t_min10/max10'] = data_1['t_min10']/data_1['t_max10']\n",
    "data_1['t_min20/max20'] = data_1['t_min20']/data_1['t_max20']\n",
    "\n",
    "# comparações entre mínimo, máximo e médias móveis\n",
    "data_1['t_ma10/max20'] = data_1['t_ma10']/data_1['t_max20']\n",
    "data_1['t_ma10/ma20'] = data_1['t_ma10']/data_1['t_ma20']\n",
    "data_1['t_ma10/min20'] = data_1['t_ma10']/data_1['t_min20']\n",
    "data_1['t_ma10/min10'] = data_1['t_ma10']/data_1['t_min10']\n",
    "data_1['t_ma10/max10'] = data_1['t_ma10']/data_1['t_max10']\n",
    "data_1['t_ma20/max20'] = data_1['t_ma20']/data_1['t_max20']\n",
    "data_1['t_ma20/min20'] = data_1['t_ma20']/data_1['t_min20']\n",
    "data_1['t_ma20/min10'] = data_1['t_ma20']/data_1['t_min10']\n",
    "data_1['t_ma20/max10'] = data_1['t_ma20']/data_1['t_max10']\n",
    "data_1['t_ma10_maior_max20'] = np.where((data_1.t_ma10 > data_1.t_max20),1,0)\n",
    "data_1['t_ma20_menor_min10'] = np.where((data_1.t_ma20 < data_1.t_min10),1,0)\n",
    "data_1['t_ma10_menor_min20'] = np.where((data_1.t_ma10 < data_1.t_min20),1,0)\n",
    "\n",
    "# comparações entre ponto atual e máximos e mínimos de 10 e 20 minutos\n",
    "data_1['t_valor_menor_min20'] = np.where((data_1.TICKVOL < data_1.t_min20),1,0)\n",
    "data_1['t_valor_menor_min10'] = np.where((data_1.TICKVOL < data_1.t_min10),1,0)\n",
    "data_1['t_valor_maior_max20'] = np.where((data_1.TICKVOL > data_1.t_max20),1,0)\n",
    "data_1['t_valor_maior_max10'] = np.where((data_1.TICKVOL > data_1.t_max10),1,0)\n",
    "\n",
    "# criação das bollinger bands considerando n = 20 minutos e 2 desvios padrão\n",
    "indicator_aa = BollingerBands(close=data_1[\"TICKVOL\"], n=20, ndev=2)\n",
    "data_1['t_bb_bbp'] = indicator_aa.bollinger_pband()\n",
    "data_1['t_bb_upper'] = indicator_aa.bollinger_hband_indicator()\n",
    "data_1['t_bb_lower'] = indicator_aa.bollinger_lband_indicator()\n",
    "\n",
    "# criação do tickvol lagado de até 3 minutos\n",
    "data_1['t_valor_l1'] = data_1['TICKVOL'].shift(1)\n",
    "data_1['t_valor_l2'] = data_1['TICKVOL'].shift(2)\n",
    "data_1['t_valor_l3'] = data_1['TICKVOL'].shift(3)\n",
    "# comparação entre o tickvol atual e o tickvol lagado\n",
    "data_1['t_diff_l1'] = data_1['TICKVOL']  - data_1['t_valor_l1']\n",
    "data_1['t_diff_l2'] = data_1['TICKVOL']  - data_1['t_valor_l2']\n",
    "data_1['t_diff_l3'] = data_1['TICKVOL']  - data_1['t_valor_l3']\n",
    "# comparação entre o tickvol lagado de 1 minuto e tickvol lagado de 20 minutos\n",
    "data_1['t_lag1/lag20'] = data_1['TICKVOL'].shift(1)/data_1['TICKVOL'].shift(20)\n",
    "data_1['t_lag1/lag10'] = data_1['TICKVOL'].shift(1)/data_1['TICKVOL'].shift(10)\n",
    "data_1['t_coef_ang20'] = (data_1['t_valor_l1'] - data_1['TICKVOL'].shift(20))/20\n",
    "data_1['t_coef_ang10'] = (data_1['t_valor_l1'] - data_1['TICKVOL'].shift(10))/10\n",
    "\n",
    "# quantidade de vezes que o tickvol fechou positivo ou negativo em relação ao minuto anterior \n",
    "# nos últimos 20 minutos e 10 minutos\n",
    "c = 0\n",
    "d = 0\n",
    "for i in range(1,19):\n",
    "    c = np.where((data_1['TICKVOL'].shift(i) > data_1['TICKVOL'].shift(i+1)),1,0) + c\n",
    "    d = np.where((data_1['TICKVOL'].shift(i) < data_1['TICKVOL'].shift(i+1)),1,0) + d\n",
    "    \n",
    "e = 0\n",
    "f = 0\n",
    "for i in range(1,9):\n",
    "    e = np.where((data_1['TICKVOL'].shift(i) > data_1['TICKVOL'].shift(i+1)),1,0) + e\n",
    "    f = np.where((data_1['TICKVOL'].shift(i) < data_1['TICKVOL'].shift(i+1)),1,0) + f\n",
    "    \n",
    "data_1['t_qtde_vezes_positivo20'] = c\n",
    "data_1['t_qtde_vezes_negativo20'] = d\n",
    "data_1['t_qtde_vezes_positivo10'] = e\n",
    "data_1['t_qtde_vezes_negativo10'] = f\n",
    "\n",
    "# variáveis lagadas vs mínimos, média móvel \n",
    "data_1['t_lag1/min20'] = data_1['TICKVOL'].shift(1)/data_1['t_min20']\n",
    "data_1['t_lag2/min20'] = data_1['TICKVOL'].shift(2)/data_1['t_min20']\n",
    "data_1['t_lag3/min20'] = data_1['TICKVOL'].shift(3)/data_1['t_min20']\n",
    "data_1['t_lag1/ma20'] = data_1['TICKVOL'].shift(1)/data_1['t_ma20']\n",
    "\n",
    "# variável média vs máximo\n",
    "data_1['t_ma3/max3'] = a.rolling(3).mean()/a.rolling(3).max()\n",
    "\n",
    "# normalizando\n",
    "media = data_1['t_ma20'].mean()\n",
    "data_1['t_ma20'] = data_1['t_ma20']/media\n",
    "media = data_1['t_ma10'].mean()\n",
    "data_1['t_ma10'] = data_1['t_ma10']/media\n",
    "\n",
    "media = data_1['t_max20'].mean()\n",
    "data_1['t_max20'] = data_1['t_max20']/media\n",
    "media = data_1['t_max10'].mean()\n",
    "data_1['t_max10'] = data_1['t_max10']/media\n",
    "media = data_1['t_min20'].mean()\n",
    "data_1['t_min20'] = data_1['t_min20']/media\n",
    "media = data_1['t_min10'].mean()\n",
    "data_1['t_min10'] = data_1['t_min10']/media\n",
    "\n",
    "media = data_1['t_bb_upper'].mean()\n",
    "data_1['t_bb_upper'] = data_1['t_bb_upper']/media\n",
    "media = data_1['t_bb_lower'].mean()\n",
    "data_1['t_bb_lower'] = data_1['t_bb_lower']/media\n",
    "\n",
    "media = data_1['t_valor_l1'].mean()\n",
    "data_1['t_valor_l1'] = data_1['t_valor_l1']/media\n",
    "media = data_1['t_valor_l2'].mean()\n",
    "data_1['t_valor_l2'] = data_1['t_valor_l2']/media\n",
    "media = data_1['t_valor_l3'].mean()\n",
    "data_1['t_valor_l3'] = data_1['t_valor_l3']/media\n",
    "\n",
    "media = data_1['t_diff_l1'].mean()\n",
    "data_1['t_diff_l1'] = data_1['t_diff_l1']/media\n",
    "media = data_1['t_diff_l2'].mean()\n",
    "data_1['t_diff_l2'] = data_1['t_diff_l2']/media\n",
    "media = data_1['t_diff_l3'].mean()\n",
    "data_1['t_diff_l3'] = data_1['t_diff_l3']/media\n",
    "\n",
    "media = data_1['t_coef_ang20'].mean()\n",
    "data_1['t_coef_ang20'] = data_1['t_coef_ang20']/media\n",
    "media = data_1['t_coef_ang10'].mean()\n",
    "data_1['t_coef_ang10'] = data_1['t_coef_ang10']/media\n",
    "\n",
    "media = data_1['t_qtde_vezes_positivo20'].mean()\n",
    "data_1['t_qtde_vezes_positivo20'] = data_1['t_qtde_vezes_positivo20']/media\n",
    "media = data_1['t_qtde_vezes_negativo20'].mean()\n",
    "data_1['t_qtde_vezes_negativo20'] = data_1['t_qtde_vezes_negativo20']/media\n",
    "media = data_1['t_qtde_vezes_positivo10'].mean()\n",
    "data_1['t_qtde_vezes_positivo10'] = data_1['t_qtde_vezes_positivo10']/media\n",
    "media = data_1['t_qtde_vezes_negativo10'].mean()\n",
    "data_1['t_qtde_vezes_negativo10'] = data_1['t_qtde_vezes_negativo10']/media\n",
    "\n",
    "media = data_1['TICKVOL'].mean()\n",
    "data_1['TICKVOL'] = data_1['TICKVOL']/media\n",
    "\n",
    "#####################\n",
    "### target lagado ###\n",
    "#####################\n",
    "data_1['valor_target_l1'] = data_1['target'].shift(1)\n",
    "data_1['valor_target_l2'] = data_1['target'].shift(2)\n",
    "data_1['valor_target_l3'] = data_1['target'].shift(3)\n",
    "data_1['valor_target_l4'] = data_1['target'].shift(4)\n",
    "data_1['valor_target_l5'] = data_1['target'].shift(5)\n",
    "data_1['valor_target_l6'] = data_1['target'].shift(6)\n",
    "data_1['valor_target_l7'] = data_1['target'].shift(7)\n",
    "data_1['valor_target_l8'] = data_1['target'].shift(8)\n",
    "data_1['valor_target_l9'] = data_1['target'].shift(9)\n",
    "data_1['valor_target_l10'] = data_1['target'].shift(10)\n",
    "data_1['valor_target_l11'] = data_1['target'].shift(11)\n",
    "data_1['valor_target_l12'] = data_1['target'].shift(12)\n",
    "data_1['valor_target_l13'] = data_1['target'].shift(13)\n",
    "data_1['valor_target_l14'] = data_1['target'].shift(14)\n",
    "data_1['valor_target_l15'] = data_1['target'].shift(15)\n",
    "data_1['valor_target_l16'] = data_1['target'].shift(16)\n",
    "data_1['valor_target_l17'] = data_1['target'].shift(17)\n",
    "data_1['valor_target_l18'] = data_1['target'].shift(18)\n",
    "data_1['valor_target_l19'] = data_1['target'].shift(19)\n",
    "data_1['valor_target_l20'] = data_1['target'].shift(20)\n",
    "\n",
    "###################################\n",
    "### variáveis baseadas em datas ###\n",
    "###################################\n",
    "# dia da semana\n",
    "data_1['dia_semana'] = pd.DatetimeIndex(data_1['datetime']).weekday # 0 é segunda #\n",
    "# hora do dia\n",
    "data_1['hora_do_dia'] = pd.DatetimeIndex(data_1['datetime']).hour\n",
    "# período do mês, inicial, meio ou final\n",
    "data_1['dia_do_mes'] = np.where((pd.DatetimeIndex(data_1['datetime']).day < 10),1,\n",
    "                               np.where((pd.DatetimeIndex(data_1['datetime']).day < 20),2,3))\n",
    "# período do dia\n",
    "data_1['periodo_dia'] = np.where((pd.DatetimeIndex(data_1['datetime']).hour < 12),1,\n",
    "                               np.where((pd.DatetimeIndex(data_1['datetime']).hour < 15),2,3))\n",
    "\n",
    "###############\n",
    "### ajustes ###\n",
    "###############\n",
    "# retira observações vazias\n",
    "data_1 = data_1.dropna()\n",
    "data_1.reset_index(drop = True, inplace = True)\n",
    "\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
      "TRAIN: [    0     1     2 ... 12120 12121 12122] TEST: [12123 12124 12125 ... 24242 24243 24244]\n",
      "TRAIN: [    0     1     2 ... 24242 24243 24244] TEST: [24245 24246 24247 ... 36364 36365 36366]\n",
      "TRAIN: [    0     1     2 ... 36364 36365 36366] TEST: [36367 36368 36369 ... 48486 48487 48488]\n",
      "TRAIN: [    0     1     2 ... 48486 48487 48488] TEST: [48489 48490 48491 ... 60608 60609 60610]\n",
      "TRAIN: [    0     1     2 ... 60608 60609 60610] TEST: [60611 60612 60613 ... 72730 72731 72732]\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "treino_1, teste_1 = split_treino_test(data_1)\n",
    "\n",
    ">>> data_1X = treino_1.drop(columns=['target', 'datetime'])\n",
    ">>> data_1X\n",
    "\n",
    ">>> data_1y = treino_1[['target']]\n",
    ">>> data_1y\n",
    "\n",
    ">>> tscv = TimeSeriesSplit()\n",
    ">>> print(tscv)\n",
    "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
    ">>> for train_index, test_index in tscv.split(treino_1):\n",
    "...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "...     X_teste_1= data_1X.loc[test_index]\n",
    "...     X_treino_1= data_1X.loc[train_index]\n",
    "...     y_treino_1 = data_1y.loc[train_index]\n",
    "...     y_teste_1 = data_1y.loc[test_index]\n",
    "\n",
    "...     X_treino_1['testeR']=train_index\n",
    "...     y_treino_1['testeR']=train_index\n",
    "...     X_teste_1['testeR']=test_index\n",
    "...     y_teste_1['testeR']=test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_treino_cv1 = X_treino_1[X_treino_1['testeR'] <= 12122]\n",
    "X_treino_cv1 = X_treino_cv1.copy().drop(columns = ['testeR'])\n",
    "X_teste_cv1 = X_treino_1[X_treino_1['testeR'] >= 12123]\n",
    "X_teste_cv1 = X_teste_cv1[X_teste_cv1['testeR'] <= 24244]\n",
    "X_teste_cv1 = X_teste_cv1.copy().drop(columns = ['testeR'])\n",
    "\n",
    "X_treino_cv2 = X_treino_1[X_treino_1['testeR'] <= 24244]\n",
    "X_treino_cv2 = X_treino_cv2.copy().drop(columns = ['testeR'])\n",
    "X_teste_cv2 = X_treino_1[X_treino_1['testeR'] >= 24245]\n",
    "X_teste_cv2 = X_teste_cv2[X_teste_cv2['testeR'] <= 36366]\n",
    "X_teste_cv2 = X_teste_cv2.copy().drop(columns = ['testeR'])\n",
    "\n",
    "X_treino_cv3 = X_treino_1[X_treino_1['testeR'] <= 36366]\n",
    "X_treino_cv3 = X_treino_cv3.copy().drop(columns = ['testeR'])\n",
    "X_teste_cv3 = X_treino_1[X_treino_1['testeR'] >= 36367]\n",
    "X_teste_cv3 = X_teste_cv3[X_teste_cv3['testeR'] <= 48488]\n",
    "X_teste_cv3 = X_teste_cv3.copy().drop(columns = ['testeR'])\n",
    "\n",
    "X_treino_cv4 = X_treino_1[X_treino_1['testeR'] <= 48488]\n",
    "X_treino_cv4 = X_treino_cv4.copy().drop(columns = ['testeR'])\n",
    "X_teste_cv4 = X_treino_1[X_treino_1['testeR'] >= 48489]\n",
    "X_teste_cv4 = X_teste_cv4[X_teste_cv4['testeR'] <= 60610]\n",
    "X_teste_cv4 = X_teste_cv4.copy().drop(columns = ['testeR'])\n",
    "\n",
    "X_treino_cv5 = X_treino_1.copy().drop(columns = ['testeR'])\n",
    "X_teste_cv5 = X_teste_1.copy().drop(columns = ['testeR'])\n",
    "\n",
    "\n",
    "y_treino_cv1 = y_treino_1[y_treino_1['testeR'] <= 12122]\n",
    "y_treino_cv1 = y_treino_cv1.copy().drop(columns = ['testeR'])\n",
    "y_teste_cv1 = y_treino_1[y_treino_1['testeR'] >= 12123]\n",
    "y_teste_cv1 = y_teste_cv1[y_teste_cv1['testeR'] <= 24244]\n",
    "y_teste_cv1 = y_teste_cv1.copy().drop(columns = ['testeR'])\n",
    "\n",
    "y_treino_cv2 = y_treino_1[y_treino_1['testeR'] <= 24244]\n",
    "y_treino_cv2 = y_treino_cv2.copy().drop(columns = ['testeR'])\n",
    "y_teste_cv2 = y_treino_1[y_treino_1['testeR'] >= 24245]\n",
    "y_teste_cv2 = y_teste_cv2[y_teste_cv2['testeR'] <= 36366]\n",
    "y_teste_cv2 = y_teste_cv2.copy().drop(columns = ['testeR'])\n",
    "\n",
    "y_treino_cv3 = y_treino_1[y_treino_1['testeR'] <= 36366]\n",
    "y_treino_cv3 = y_treino_cv3.copy().drop(columns = ['testeR'])\n",
    "y_teste_cv3 = y_treino_1[y_treino_1['testeR'] >= 36367]\n",
    "y_teste_cv3 = y_teste_cv3[y_teste_cv3['testeR'] <= 48488]\n",
    "y_teste_cv3 = y_teste_cv3.copy().drop(columns = ['testeR'])\n",
    "\n",
    "y_treino_cv4 = y_treino_1[y_treino_1['testeR'] <= 48488]\n",
    "y_treino_cv4 = y_treino_cv4.copy().drop(columns = ['testeR'])\n",
    "y_teste_cv4 = y_treino_1[y_treino_1['testeR'] >= 48489]\n",
    "y_teste_cv4 = y_teste_cv4[y_teste_cv4['testeR'] <= 60610]\n",
    "y_teste_cv4 = y_teste_cv4.copy().drop(columns = ['testeR'])\n",
    "\n",
    "y_treino_cv5 = y_treino_1.copy().drop(columns = ['testeR'])\n",
    "y_teste_cv5 = y_teste_1.copy().drop(columns = ['testeR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treino k-fold1\n",
      "[0.6902827620506287, 0.6262476444244385]\n",
      "teste validação k-fold1\n",
      "[0.6909699440002441, 0.5966837406158447]\n",
      "treino k-fold2\n",
      "[0.6867834329605103, 0.6114662885665894]\n",
      "teste validação k-fold2\n",
      "[0.6897225379943848, 0.5635208487510681]\n",
      "treino k-fold3\n",
      "[0.6845958232879639, 0.5954849123954773]\n",
      "teste validação k-fold3\n",
      "[0.6901473999023438, 0.5419072508811951]\n",
      "treino k-fold4\n",
      "[0.6840112805366516, 0.5820907950401306]\n",
      "teste validação k-fold4\n",
      "[0.6872687339782715, 0.5591486692428589]\n",
      "treino k-fold5\n",
      "[0.6833534836769104, 0.577502429485321]\n",
      "teste validação k-fold5\n",
      "[0.6858381032943726, 0.563438355922699]\n",
      "Acurácia - Teste Validação\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5649397730827331"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################\n",
    "### Criação da estrutura da Rede Neural ###\n",
    "###########################################\n",
    "modelo = keras.Sequential()\n",
    "# criação da camada de entrada, ativação relu\n",
    "modelo.add(keras.layers.Dense(128, activation='relu', input_shape=(128,)))\n",
    "# criação da camada escondida com 3 neurônios, ativação relu\n",
    "modelo.add(keras.layers.Dense(3, activation='relu'))\n",
    "# criação da camada de saída, ativação sigmóide para saída em probabilidade\n",
    "modelo.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# alteração do tamanho do learning rate do otimizador SGD\n",
    "sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "modelo.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "########################################\n",
    "### treino sem cv1, avaliação em cv1 ###\n",
    "########################################\n",
    "historico1 = modelo.fit(x=X_treino_cv1, y=y_treino_cv1,\n",
    "                       epochs=10,\n",
    "                       batch_size=64, \n",
    "                       verbose = 0,\n",
    "                       validation_data=(X_teste_cv1, y_teste_cv1)\n",
    "                      )\n",
    "print('treino k-fold1')\n",
    "score_n1 = modelo.evaluate(X_treino_cv1, y_treino_cv1, verbose=0)\n",
    "print(score_n1)\n",
    "print('teste validação k-fold1')\n",
    "score_n1_t = modelo.evaluate(X_teste_cv1, y_teste_cv1, verbose=0)\n",
    "print(score_n1_t)\n",
    "\n",
    "########################################\n",
    "### treino sem cv2, avaliação em cv2 ###\n",
    "########################################\n",
    "historico2 = modelo.fit(x=X_treino_cv2, y=y_treino_cv2,\n",
    "                       epochs=10,\n",
    "                       batch_size=64, \n",
    "                       verbose = 0,\n",
    "                       validation_data=(X_teste_cv2, y_teste_cv2)\n",
    "                      )\n",
    "print('treino k-fold2')\n",
    "score_n2 = modelo.evaluate(X_treino_cv2, y_treino_cv2, verbose=0)\n",
    "print(score_n2)\n",
    "print('teste validação k-fold2')\n",
    "score_n2_t = modelo.evaluate(X_teste_cv2, y_teste_cv2, verbose=0)\n",
    "print(score_n2_t)\n",
    "\n",
    "########################################\n",
    "### treino sem cv3, avaliação em cv3 ###\n",
    "########################################\n",
    "historico3 = modelo.fit(x=X_treino_cv3, y=y_treino_cv3,\n",
    "                       epochs=10,\n",
    "                       batch_size=64, \n",
    "                       verbose = 0,\n",
    "                       validation_data=(X_teste_cv3, y_teste_cv3)\n",
    "                      )\n",
    "print('treino k-fold3')\n",
    "score_n3 = modelo.evaluate(X_treino_cv3, y_treino_cv3, verbose=0)\n",
    "print(score_n3)\n",
    "print('teste validação k-fold3')\n",
    "score_n3_t = modelo.evaluate(X_teste_cv3, y_teste_cv3, verbose=0)\n",
    "print(score_n3_t)\n",
    "\n",
    "########################################\n",
    "### treino sem cv4, avaliação em cv4 ###\n",
    "########################################\n",
    "historico4 = modelo.fit(x=X_treino_cv4, y=y_treino_cv4,\n",
    "                       epochs=10,\n",
    "                       batch_size=64, \n",
    "                       verbose = 0,\n",
    "                       validation_data=(X_teste_cv4, y_teste_cv4)\n",
    "                      )\n",
    "print('treino k-fold4')\n",
    "score_n4 = modelo.evaluate(X_treino_cv4, y_treino_cv4, verbose=0)\n",
    "print(score_n4)\n",
    "print('teste validação k-fold4')\n",
    "score_n4_t = modelo.evaluate(X_teste_cv4, y_teste_cv4, verbose=0)\n",
    "print(score_n4_t)\n",
    "\n",
    "########################################\n",
    "### treino sem cv5, avaliação em cv5 ###\n",
    "########################################\n",
    "historico5 = modelo.fit(x=X_treino_cv5, y=y_treino_cv5,\n",
    "                       epochs=10,\n",
    "                       batch_size=64, \n",
    "                       verbose = 0,\n",
    "                       validation_data=(X_teste_cv5, y_teste_cv5)\n",
    "                      )\n",
    "print('treino k-fold5')\n",
    "score_n5 = modelo.evaluate(X_treino_cv5, y_treino_cv5, verbose=0)\n",
    "print(score_n5)\n",
    "print('teste validação k-fold5')\n",
    "score_n5_t = modelo.evaluate(X_teste_cv5, y_teste_cv5, verbose=0)\n",
    "print(score_n5_t)\n",
    "\n",
    "# avaliação da acurácia nos k-folds\n",
    "print('Acurácia - Teste Validação')\n",
    "(score_n1_t[1]+score_n2_t[1]+score_n3_t[1]+score_n4_t[1]+score_n5_t[1])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treino final\n",
      "Epoch 1/10\n",
      "1137/1137 [==============================] - 7s 7ms/step - loss: 19.4732 - accuracy: 0.5749A: 0s - loss: 22.2951 - accuracy - ETA: 0s - loss: 20.9616 - acc\n",
      "Epoch 2/10\n",
      "1137/1137 [==============================] - 7s 6ms/step - loss: 0.6922 - accuracy: 0.5752: \n",
      "Epoch 3/10\n",
      "1137/1137 [==============================] - 6s 5ms/step - loss: 0.6917 - accuracy: 0.5752\n",
      "Epoch 4/10\n",
      "1137/1137 [==============================] - 5s 5ms/step - loss: 0.6911 - accuracy: 0.5752\n",
      "Epoch 5/10\n",
      "1137/1137 [==============================] - 6s 5ms/step - loss: 0.6906 - accuracy: 0.5752\n",
      "Epoch 6/10\n",
      "1137/1137 [==============================] - 6s 5ms/step - loss: 0.6901 - accuracy: 0.5752\n",
      "Epoch 7/10\n",
      "1137/1137 [==============================] - 6s 5ms/step - loss: 0.6897 - accuracy: 0.5752\n",
      "Epoch 8/10\n",
      "1137/1137 [==============================] - 5s 5ms/step - loss: 0.6892 - accuracy: 0.5752\n",
      "Epoch 9/10\n",
      "1137/1137 [==============================] - 7s 6ms/step - loss: 0.6888 - accuracy: 0.5752\n",
      "Epoch 10/10\n",
      "1137/1137 [==============================] - 7s 6ms/step - loss: 0.6885 - accuracy: 0.5752\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################\n",
    "### Criação do modelo final ###\n",
    "###############################\n",
    "\n",
    "X_treino_final = data_1X\n",
    "y_treino_final = data_1y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Criação da estrutura da Rede Neural\n",
    "modelo = keras.Sequential()\n",
    "# criação da camada de entrada, ativação relu\n",
    "modelo.add(keras.layers.Dense(128, activation='relu', input_shape=(128,))) \n",
    "# criação da camada escondida com 3 neurônios, ativação relu\n",
    "modelo.add(keras.layers.Dense(3, activation='relu'))\n",
    "# criação da camada de saída, ativação sigmóide para saída em probabilidade\n",
    "modelo.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# alteração do tamanho do learning rate do otimizador SGD\n",
    "sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "modelo.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# treino final\n",
    "print('treino final')\n",
    "historico1 = modelo.fit(x=X_treino_final, y=y_treino_final,\n",
    "                       epochs=10,\n",
    "                       batch_size=64\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado na amostra de teste\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6881194114685059, 0.5771803259849548]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##################################\n",
    "### Avaliação na amostra teste ###\n",
    "##################################\n",
    "\n",
    "X_teste_1 = teste_1.copy().drop(columns = ['target', \"datetime\"])\n",
    "y_teste_1 = teste_1[['target']]\n",
    "# avaliação na amostra teste\n",
    "score_n = modelo.evaluate(X_teste_1, y_teste_1, verbose=0)\n",
    "print('resultado na amostra de teste')\n",
    "score_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13547,     0],\n",
       "       [ 9924,     0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste_1['y_pred'] = (modelo.predict(X_teste_1) > 0.5).astype(\"int32\")\n",
    "y_teste_1\n",
    "\n",
    "##########################\n",
    "### Matriz de confusão ###\n",
    "##########################\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_teste_1['target'],y_teste_1['y_pred'])\n",
    "cnf_matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
